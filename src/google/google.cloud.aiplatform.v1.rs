// This file is @generated by prost-build.
/// Schema is used to define the format of input/output data. Represents a select
/// subset of an [OpenAPI 3.0 schema
/// object](<https://spec.openapis.org/oas/v3.0.3#schema>). More fields may be
/// added in the future as needed.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Schema {
    /// Optional. The type of the data.
    #[prost(enumeration = "Type", tag = "1")]
    pub r#type: i32,
    /// Optional. The format of the data.
    /// Supported formats:
    ///   for NUMBER type: "float", "double"
    ///   for INTEGER type: "int32", "int64"
    ///   for STRING type: "email", "byte", etc
    #[prost(string, tag = "7")]
    pub format: ::prost::alloc::string::String,
    /// Optional. The title of the Schema.
    #[prost(string, tag = "24")]
    pub title: ::prost::alloc::string::String,
    /// Optional. The description of the data.
    #[prost(string, tag = "8")]
    pub description: ::prost::alloc::string::String,
    /// Optional. Indicates if the value may be null.
    #[prost(bool, tag = "6")]
    pub nullable: bool,
    /// Optional. Default value of the data.
    #[prost(message, optional, tag = "23")]
    pub default: ::core::option::Option<::prost_types::Value>,
    /// Optional. SCHEMA FIELDS FOR TYPE ARRAY
    /// Schema of the elements of Type.ARRAY.
    #[prost(message, optional, boxed, tag = "2")]
    pub items: ::core::option::Option<::prost::alloc::boxed::Box<Schema>>,
    /// Optional. Minimum number of the elements for Type.ARRAY.
    #[prost(int64, tag = "21")]
    pub min_items: i64,
    /// Optional. Maximum number of the elements for Type.ARRAY.
    #[prost(int64, tag = "22")]
    pub max_items: i64,
    /// Optional. Possible values of the element of Type.STRING with enum format.
    /// For example we can define an Enum Direction as :
    /// {type:STRING, format:enum, enum:\["EAST", NORTH", "SOUTH", "WEST"\]}
    #[prost(string, repeated, tag = "9")]
    pub r#enum: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. SCHEMA FIELDS FOR TYPE OBJECT
    /// Properties of Type.OBJECT.
    #[prost(map = "string, message", tag = "3")]
    pub properties: ::std::collections::HashMap<::prost::alloc::string::String, Schema>,
    /// Optional. Required properties of Type.OBJECT.
    #[prost(string, repeated, tag = "5")]
    pub required: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. Minimum number of the properties for Type.OBJECT.
    #[prost(int64, tag = "14")]
    pub min_properties: i64,
    /// Optional. Maximum number of the properties for Type.OBJECT.
    #[prost(int64, tag = "15")]
    pub max_properties: i64,
    /// Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER
    /// Minimum value of the Type.INTEGER and Type.NUMBER
    #[prost(double, tag = "16")]
    pub minimum: f64,
    /// Optional. Maximum value of the Type.INTEGER and Type.NUMBER
    #[prost(double, tag = "17")]
    pub maximum: f64,
    /// Optional. SCHEMA FIELDS FOR TYPE STRING
    /// Minimum length of the Type.STRING
    #[prost(int64, tag = "18")]
    pub min_length: i64,
    /// Optional. Maximum length of the Type.STRING
    #[prost(int64, tag = "19")]
    pub max_length: i64,
    /// Optional. Pattern of the Type.STRING to restrict a string to a regular
    /// expression.
    #[prost(string, tag = "20")]
    pub pattern: ::prost::alloc::string::String,
    /// Optional. Example of the object. Will only populated when the object is the
    /// root.
    #[prost(message, optional, tag = "4")]
    pub example: ::core::option::Option<::prost_types::Value>,
}
/// Type contains the list of OpenAPI data types as defined by
/// <https://swagger.io/docs/specification/data-models/data-types/>
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum Type {
    /// Not specified, should not be used.
    Unspecified = 0,
    /// OpenAPI string type
    String = 1,
    /// OpenAPI number type
    Number = 2,
    /// OpenAPI integer type
    Integer = 3,
    /// OpenAPI boolean type
    Boolean = 4,
    /// OpenAPI array type
    Array = 5,
    /// OpenAPI object type
    Object = 6,
}
impl Type {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Type::Unspecified => "TYPE_UNSPECIFIED",
            Type::String => "STRING",
            Type::Number => "NUMBER",
            Type::Integer => "INTEGER",
            Type::Boolean => "BOOLEAN",
            Type::Array => "ARRAY",
            Type::Object => "OBJECT",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TYPE_UNSPECIFIED" => Some(Self::Unspecified),
            "STRING" => Some(Self::String),
            "NUMBER" => Some(Self::Number),
            "INTEGER" => Some(Self::Integer),
            "BOOLEAN" => Some(Self::Boolean),
            "ARRAY" => Some(Self::Array),
            "OBJECT" => Some(Self::Object),
            _ => None,
        }
    }
}
/// Tool details that the model may use to generate response.
///
/// A `Tool` is a piece of code that enables the system to interact with
/// external systems to perform an action, or set of actions, outside of
/// knowledge and scope of the model. A Tool object should contain exactly
/// one type of Tool (e.g FunctionDeclaration, Retrieval or
/// GoogleSearchRetrieval).
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Tool {
    /// Optional. Function tool type.
    /// One or more function declarations to be passed to the model along with the
    /// current user query. Model may decide to call a subset of these functions
    /// by populating [FunctionCall][content.part.function_call] in the response.
    /// User should provide a [FunctionResponse][content.part.function_response]
    /// for each function call in the next turn. Based on the function responses,
    /// Model will generate the final response back to the user.
    /// Maximum 64 function declarations can be provided.
    #[prost(message, repeated, tag = "1")]
    pub function_declarations: ::prost::alloc::vec::Vec<FunctionDeclaration>,
    /// Optional. Retrieval tool type.
    /// System will always execute the provided retrieval tool(s) to get external
    /// knowledge to answer the prompt. Retrieval results are presented to the
    /// model for generation.
    #[prost(message, optional, tag = "2")]
    pub retrieval: ::core::option::Option<Retrieval>,
    /// Optional. GoogleSearchRetrieval tool type.
    /// Specialized retrieval tool that is powered by Google search.
    #[prost(message, optional, tag = "3")]
    pub google_search_retrieval: ::core::option::Option<GoogleSearchRetrieval>,
}
/// Structured representation of a function declaration as defined by the
/// [OpenAPI 3.0 specification](<https://spec.openapis.org/oas/v3.0.3>). Included
/// in this declaration are the function name and parameters. This
/// FunctionDeclaration is a representation of a block of code that can be used
/// as a `Tool` by the model and executed by the client.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionDeclaration {
    /// Required. The name of the function to call.
    /// Must start with a letter or an underscore.
    /// Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a
    /// maximum length of 64.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Optional. Description and purpose of the function.
    /// Model uses it to decide how and whether to call the function.
    #[prost(string, tag = "2")]
    pub description: ::prost::alloc::string::String,
    /// Optional. Describes the parameters to this function in JSON Schema Object
    /// format. Reflects the Open API 3.03 Parameter Object. string Key: the name
    /// of the parameter. Parameter names are case sensitive. Schema Value: the
    /// Schema defining the type used for the parameter. For function with no
    /// parameters, this can be left unset. Parameter names must start with a
    /// letter or an underscore and must only contain chars a-z, A-Z, 0-9, or
    /// underscores with a maximum length of 64. Example with 1 required and 1
    /// optional parameter: type: OBJECT properties:
    ///   param1:
    ///     type: STRING
    ///   param2:
    ///     type: INTEGER
    /// required:
    ///   - param1
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<Schema>,
}
/// A predicted \[FunctionCall\] returned from the model that contains a string
/// representing the \[FunctionDeclaration.name\] and a structured JSON object
/// containing the parameters and their values.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionCall {
    /// Required. The name of the function to call.
    /// Matches \[FunctionDeclaration.name\].
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Optional. Required. The function parameters and values in JSON object
    /// format. See \[FunctionDeclaration.parameters\] for parameter details.
    #[prost(message, optional, tag = "2")]
    pub args: ::core::option::Option<::prost_types::Struct>,
}
/// The result output from a \[FunctionCall\] that contains a string representing
/// the \[FunctionDeclaration.name\] and a structured JSON object containing any
/// output from the function is used as context to the model. This should contain
/// the result of a \[FunctionCall\] made based on model prediction.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionResponse {
    /// Required. The name of the function to call.
    /// Matches \[FunctionDeclaration.name\] and \[FunctionCall.name\].
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Required. The function response in JSON object format.
    #[prost(message, optional, tag = "2")]
    pub response: ::core::option::Option<::prost_types::Struct>,
}
/// Defines a retrieval tool that model can call to access external knowledge.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Retrieval {
    /// Optional. Disable using the result from this tool in detecting grounding
    /// attribution. This does not affect how the result is given to the model for
    /// generation.
    #[prost(bool, tag = "3")]
    pub disable_attribution: bool,
    /// The source of the retrieval.
    #[prost(oneof = "retrieval::Source", tags = "2")]
    pub source: ::core::option::Option<retrieval::Source>,
}
/// Nested message and enum types in `Retrieval`.
pub mod retrieval {
    /// The source of the retrieval.
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Source {
        /// Set to use data source powered by Vertex AI Search.
        #[prost(message, tag = "2")]
        VertexAiSearch(super::VertexAiSearch),
    }
}
/// Retrieve from Vertex AI Search datastore for grounding.
/// See <https://cloud.google.com/vertex-ai-search-and-conversation>
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct VertexAiSearch {
    /// Required. Fully-qualified Vertex AI Search's datastore resource ID.
    /// Format:
    /// `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`
    #[prost(string, tag = "1")]
    pub datastore: ::prost::alloc::string::String,
}
/// Tool to retrieve public web data for grounding, powered by Google.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct GoogleSearchRetrieval {}
/// Tool config. This config is shared for all tools provided in the request.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ToolConfig {
    /// Optional. Function calling config.
    #[prost(message, optional, tag = "1")]
    pub function_calling_config: ::core::option::Option<FunctionCallingConfig>,
}
/// Function calling config.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionCallingConfig {
    /// Optional. Function calling mode.
    #[prost(enumeration = "function_calling_config::Mode", tag = "1")]
    pub mode: i32,
    /// Optional. Function names to call. Only set when the Mode is ANY. Function
    /// names should match \[FunctionDeclaration.name\]. With mode set to ANY, model
    /// will predict a function call from the set of function names provided.
    #[prost(string, repeated, tag = "2")]
    pub allowed_function_names: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// Nested message and enum types in `FunctionCallingConfig`.
pub mod function_calling_config {
    /// Function calling mode.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Mode {
        /// Unspecified function calling mode. This value should not be used.
        Unspecified = 0,
        /// Default model behavior, model decides to predict either a function call
        /// or a natural language repspose.
        Auto = 1,
        /// Model is constrained to always predicting a function call only.
        /// If "allowed_function_names" are set, the predicted function call will be
        /// limited to any one of "allowed_function_names", else the predicted
        /// function call will be any one of the provided "function_declarations".
        Any = 2,
        /// Model will not predict any function call. Model behavior is same as when
        /// not passing any function declarations.
        None = 3,
    }
    impl Mode {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Mode::Unspecified => "MODE_UNSPECIFIED",
                Mode::Auto => "AUTO",
                Mode::Any => "ANY",
                Mode::None => "NONE",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MODE_UNSPECIFIED" => Some(Self::Unspecified),
                "AUTO" => Some(Self::Auto),
                "ANY" => Some(Self::Any),
                "NONE" => Some(Self::None),
                _ => None,
            }
        }
    }
}
/// The base structured datatype containing multi-part content of a message.
///
/// A `Content` includes a `role` field designating the producer of the `Content`
/// and a `parts` field containing multi-part data that contains the content of
/// the message turn.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Content {
    /// Optional. The producer of the content. Must be either 'user' or 'model'.
    ///
    /// Useful to set for multi-turn conversations, otherwise can be left blank
    /// or unset.
    #[prost(string, tag = "1")]
    pub role: ::prost::alloc::string::String,
    /// Required. Ordered `Parts` that constitute a single message. Parts may have
    /// different IANA MIME types.
    #[prost(message, repeated, tag = "2")]
    pub parts: ::prost::alloc::vec::Vec<Part>,
}
/// A datatype containing media that is part of a multi-part `Content` message.
///
/// A `Part` consists of data which has an associated datatype. A `Part` can only
/// contain one of the accepted types in `Part.data`.
///
/// A `Part` must have a fixed IANA MIME type identifying the type and subtype
/// of the media if `inline_data` or `file_data` field is filled with raw bytes.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Part {
    #[prost(oneof = "part::Data", tags = "1, 2, 3, 5, 6")]
    pub data: ::core::option::Option<part::Data>,
    #[prost(oneof = "part::Metadata", tags = "4")]
    pub metadata: ::core::option::Option<part::Metadata>,
}
/// Nested message and enum types in `Part`.
pub mod part {
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Data {
        /// Optional. Text part (can be code).
        #[prost(string, tag = "1")]
        Text(::prost::alloc::string::String),
        /// Optional. Inlined bytes data.
        #[prost(message, tag = "2")]
        InlineData(super::Blob),
        /// Optional. URI based data.
        #[prost(message, tag = "3")]
        FileData(super::FileData),
        /// Optional. A predicted \[FunctionCall\] returned from the model that
        /// contains a string representing the \[FunctionDeclaration.name\] with the
        /// parameters and their values.
        #[prost(message, tag = "5")]
        FunctionCall(super::FunctionCall),
        /// Optional. The result output of a \[FunctionCall\] that contains a string
        /// representing the \[FunctionDeclaration.name\] and a structured JSON object
        /// containing any output from the function call. It is used as context to
        /// the model.
        #[prost(message, tag = "6")]
        FunctionResponse(super::FunctionResponse),
    }
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, Copy, PartialEq, ::prost::Oneof)]
    pub enum Metadata {
        /// Optional. Video metadata. The metadata should only be specified while the
        /// video data is presented in inline_data or file_data.
        #[prost(message, tag = "4")]
        VideoMetadata(super::VideoMetadata),
    }
}
/// Content blob.
///
/// It's preferred to send as [text][google.cloud.aiplatform.v1.Part.text]
/// directly rather than raw bytes.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Blob {
    /// Required. The IANA standard MIME type of the source data.
    #[prost(string, tag = "1")]
    pub mime_type: ::prost::alloc::string::String,
    /// Required. Raw bytes.
    #[prost(bytes = "vec", tag = "2")]
    pub data: ::prost::alloc::vec::Vec<u8>,
}
/// URI based data.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FileData {
    /// Required. The IANA standard MIME type of the source data.
    #[prost(string, tag = "1")]
    pub mime_type: ::prost::alloc::string::String,
    /// Required. URI.
    #[prost(string, tag = "2")]
    pub file_uri: ::prost::alloc::string::String,
}
/// Metadata describes the input video content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct VideoMetadata {
    /// Optional. The start offset of the video.
    #[prost(message, optional, tag = "1")]
    pub start_offset: ::core::option::Option<::prost_types::Duration>,
    /// Optional. The end offset of the video.
    #[prost(message, optional, tag = "2")]
    pub end_offset: ::core::option::Option<::prost_types::Duration>,
}
/// Generation config.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerationConfig {
    /// Optional. Controls the randomness of predictions.
    #[prost(float, optional, tag = "1")]
    pub temperature: ::core::option::Option<f32>,
    /// Optional. If specified, nucleus sampling will be used.
    #[prost(float, optional, tag = "2")]
    pub top_p: ::core::option::Option<f32>,
    /// Optional. If specified, top-k sampling will be used.
    #[prost(float, optional, tag = "3")]
    pub top_k: ::core::option::Option<f32>,
    /// Optional. Number of candidates to generate.
    #[prost(int32, optional, tag = "4")]
    pub candidate_count: ::core::option::Option<i32>,
    /// Optional. The maximum number of output tokens to generate per message.
    #[prost(int32, optional, tag = "5")]
    pub max_output_tokens: ::core::option::Option<i32>,
    /// Optional. Stop sequences.
    #[prost(string, repeated, tag = "6")]
    pub stop_sequences: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. Positive penalties.
    #[prost(float, optional, tag = "8")]
    pub presence_penalty: ::core::option::Option<f32>,
    /// Optional. Frequency penalties.
    #[prost(float, optional, tag = "9")]
    pub frequency_penalty: ::core::option::Option<f32>,
    /// Optional. Output response mimetype of the generated candidate text.
    /// Supported mimetype:
    /// - `text/plain`: (default) Text output.
    /// - `application/json`: JSON response in the candidates.
    /// The model needs to be prompted to output the appropriate response type,
    /// otherwise the behavior is undefined.
    /// This is a preview feature.
    #[prost(string, tag = "13")]
    pub response_mime_type: ::prost::alloc::string::String,
    /// Optional. The `Schema` object allows the definition of input and output
    /// data types. These types can be objects, but also primitives and arrays.
    /// Represents a select subset of an [OpenAPI 3.0 schema
    /// object](<https://spec.openapis.org/oas/v3.0.3#schema>).
    /// If set, a compatible response_mime_type must also be set.
    /// Compatible mimetypes:
    /// `application/json`: Schema for JSON response.
    #[prost(message, optional, tag = "16")]
    pub response_schema: ::core::option::Option<Schema>,
}
/// Safety settings.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct SafetySetting {
    /// Required. Harm category.
    #[prost(enumeration = "HarmCategory", tag = "1")]
    pub category: i32,
    /// Required. The harm block threshold.
    #[prost(enumeration = "safety_setting::HarmBlockThreshold", tag = "2")]
    pub threshold: i32,
    /// Optional. Specify if the threshold is used for probability or severity
    /// score. If not specified, the threshold is used for probability score.
    #[prost(enumeration = "safety_setting::HarmBlockMethod", tag = "4")]
    pub method: i32,
}
/// Nested message and enum types in `SafetySetting`.
pub mod safety_setting {
    /// Probability based thresholds levels for blocking.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum HarmBlockThreshold {
        /// Unspecified harm block threshold.
        Unspecified = 0,
        /// Block low threshold and above (i.e. block more).
        BlockLowAndAbove = 1,
        /// Block medium threshold and above.
        BlockMediumAndAbove = 2,
        /// Block only high threshold (i.e. block less).
        BlockOnlyHigh = 3,
        /// Block none.
        BlockNone = 4,
    }
    impl HarmBlockThreshold {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                HarmBlockThreshold::Unspecified => "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                HarmBlockThreshold::BlockLowAndAbove => "BLOCK_LOW_AND_ABOVE",
                HarmBlockThreshold::BlockMediumAndAbove => "BLOCK_MEDIUM_AND_ABOVE",
                HarmBlockThreshold::BlockOnlyHigh => "BLOCK_ONLY_HIGH",
                HarmBlockThreshold::BlockNone => "BLOCK_NONE",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "HARM_BLOCK_THRESHOLD_UNSPECIFIED" => Some(Self::Unspecified),
                "BLOCK_LOW_AND_ABOVE" => Some(Self::BlockLowAndAbove),
                "BLOCK_MEDIUM_AND_ABOVE" => Some(Self::BlockMediumAndAbove),
                "BLOCK_ONLY_HIGH" => Some(Self::BlockOnlyHigh),
                "BLOCK_NONE" => Some(Self::BlockNone),
                _ => None,
            }
        }
    }
    /// Probability vs severity.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum HarmBlockMethod {
        /// The harm block method is unspecified.
        Unspecified = 0,
        /// The harm block method uses both probability and severity scores.
        Severity = 1,
        /// The harm block method uses the probability score.
        Probability = 2,
    }
    impl HarmBlockMethod {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                HarmBlockMethod::Unspecified => "HARM_BLOCK_METHOD_UNSPECIFIED",
                HarmBlockMethod::Severity => "SEVERITY",
                HarmBlockMethod::Probability => "PROBABILITY",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "HARM_BLOCK_METHOD_UNSPECIFIED" => Some(Self::Unspecified),
                "SEVERITY" => Some(Self::Severity),
                "PROBABILITY" => Some(Self::Probability),
                _ => None,
            }
        }
    }
}
/// Safety rating corresponding to the generated content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct SafetyRating {
    /// Output only. Harm category.
    #[prost(enumeration = "HarmCategory", tag = "1")]
    pub category: i32,
    /// Output only. Harm probability levels in the content.
    #[prost(enumeration = "safety_rating::HarmProbability", tag = "2")]
    pub probability: i32,
    /// Output only. Harm probability score.
    #[prost(float, tag = "5")]
    pub probability_score: f32,
    /// Output only. Harm severity levels in the content.
    #[prost(enumeration = "safety_rating::HarmSeverity", tag = "6")]
    pub severity: i32,
    /// Output only. Harm severity score.
    #[prost(float, tag = "7")]
    pub severity_score: f32,
    /// Output only. Indicates whether the content was filtered out because of this
    /// rating.
    #[prost(bool, tag = "3")]
    pub blocked: bool,
}
/// Nested message and enum types in `SafetyRating`.
pub mod safety_rating {
    /// Harm probability levels in the content.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum HarmProbability {
        /// Harm probability unspecified.
        Unspecified = 0,
        /// Negligible level of harm.
        Negligible = 1,
        /// Low level of harm.
        Low = 2,
        /// Medium level of harm.
        Medium = 3,
        /// High level of harm.
        High = 4,
    }
    impl HarmProbability {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                HarmProbability::Unspecified => "HARM_PROBABILITY_UNSPECIFIED",
                HarmProbability::Negligible => "NEGLIGIBLE",
                HarmProbability::Low => "LOW",
                HarmProbability::Medium => "MEDIUM",
                HarmProbability::High => "HIGH",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "HARM_PROBABILITY_UNSPECIFIED" => Some(Self::Unspecified),
                "NEGLIGIBLE" => Some(Self::Negligible),
                "LOW" => Some(Self::Low),
                "MEDIUM" => Some(Self::Medium),
                "HIGH" => Some(Self::High),
                _ => None,
            }
        }
    }
    /// Harm severity levels.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum HarmSeverity {
        /// Harm severity unspecified.
        Unspecified = 0,
        /// Negligible level of harm severity.
        Negligible = 1,
        /// Low level of harm severity.
        Low = 2,
        /// Medium level of harm severity.
        Medium = 3,
        /// High level of harm severity.
        High = 4,
    }
    impl HarmSeverity {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                HarmSeverity::Unspecified => "HARM_SEVERITY_UNSPECIFIED",
                HarmSeverity::Negligible => "HARM_SEVERITY_NEGLIGIBLE",
                HarmSeverity::Low => "HARM_SEVERITY_LOW",
                HarmSeverity::Medium => "HARM_SEVERITY_MEDIUM",
                HarmSeverity::High => "HARM_SEVERITY_HIGH",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "HARM_SEVERITY_UNSPECIFIED" => Some(Self::Unspecified),
                "HARM_SEVERITY_NEGLIGIBLE" => Some(Self::Negligible),
                "HARM_SEVERITY_LOW" => Some(Self::Low),
                "HARM_SEVERITY_MEDIUM" => Some(Self::Medium),
                "HARM_SEVERITY_HIGH" => Some(Self::High),
                _ => None,
            }
        }
    }
}
/// A collection of source attributions for a piece of content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CitationMetadata {
    /// Output only. List of citations.
    #[prost(message, repeated, tag = "1")]
    pub citations: ::prost::alloc::vec::Vec<Citation>,
}
/// Source attributions for content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Citation {
    /// Output only. Start index into the content.
    #[prost(int32, tag = "1")]
    pub start_index: i32,
    /// Output only. End index into the content.
    #[prost(int32, tag = "2")]
    pub end_index: i32,
    /// Output only. Url reference of the attribution.
    #[prost(string, tag = "3")]
    pub uri: ::prost::alloc::string::String,
    /// Output only. Title of the attribution.
    #[prost(string, tag = "4")]
    pub title: ::prost::alloc::string::String,
    /// Output only. License of the attribution.
    #[prost(string, tag = "5")]
    pub license: ::prost::alloc::string::String,
    /// Output only. Publication date of the attribution.
    #[prost(message, optional, tag = "6")]
    pub publication_date: ::core::option::Option<super::super::super::r#type::Date>,
}
/// A response candidate generated from the model.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Candidate {
    /// Output only. Index of the candidate.
    #[prost(int32, tag = "1")]
    pub index: i32,
    /// Output only. Content parts of the candidate.
    #[prost(message, optional, tag = "2")]
    pub content: ::core::option::Option<Content>,
    /// Output only. The reason why the model stopped generating tokens.
    /// If empty, the model has not stopped generating the tokens.
    #[prost(enumeration = "candidate::FinishReason", tag = "3")]
    pub finish_reason: i32,
    /// Output only. List of ratings for the safety of a response candidate.
    ///
    /// There is at most one rating per category.
    #[prost(message, repeated, tag = "4")]
    pub safety_ratings: ::prost::alloc::vec::Vec<SafetyRating>,
    /// Output only. Describes the reason the mode stopped generating tokens in
    /// more detail. This is only filled when `finish_reason` is set.
    #[prost(string, optional, tag = "5")]
    pub finish_message: ::core::option::Option<::prost::alloc::string::String>,
    /// Output only. Source attribution of the generated content.
    #[prost(message, optional, tag = "6")]
    pub citation_metadata: ::core::option::Option<CitationMetadata>,
    /// Output only. Metadata specifies sources used to ground generated content.
    #[prost(message, optional, tag = "7")]
    pub grounding_metadata: ::core::option::Option<GroundingMetadata>,
}
/// Nested message and enum types in `Candidate`.
pub mod candidate {
    /// The reason why the model stopped generating tokens.
    /// If empty, the model has not stopped generating the tokens.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum FinishReason {
        /// The finish reason is unspecified.
        Unspecified = 0,
        /// Natural stop point of the model or provided stop sequence.
        Stop = 1,
        /// The maximum number of tokens as specified in the request was reached.
        MaxTokens = 2,
        /// The token generation was stopped as the response was flagged for safety
        /// reasons. NOTE: When streaming the Candidate.content will be empty if
        /// content filters blocked the output.
        Safety = 3,
        /// The token generation was stopped as the response was flagged for
        /// unauthorized citations.
        Recitation = 4,
        /// All other reasons that stopped the token generation
        Other = 5,
        /// The token generation was stopped as the response was flagged for the
        /// terms which are included from the terminology blocklist.
        Blocklist = 6,
        /// The token generation was stopped as the response was flagged for
        /// the prohibited contents.
        ProhibitedContent = 7,
        /// The token generation was stopped as the response was flagged for
        /// Sensitive Personally Identifiable Information (SPII) contents.
        Spii = 8,
        /// The function call generated by the model is invalid.
        MalformedFunctionCall = 9,
    }
    impl FinishReason {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                FinishReason::Unspecified => "FINISH_REASON_UNSPECIFIED",
                FinishReason::Stop => "STOP",
                FinishReason::MaxTokens => "MAX_TOKENS",
                FinishReason::Safety => "SAFETY",
                FinishReason::Recitation => "RECITATION",
                FinishReason::Other => "OTHER",
                FinishReason::Blocklist => "BLOCKLIST",
                FinishReason::ProhibitedContent => "PROHIBITED_CONTENT",
                FinishReason::Spii => "SPII",
                FinishReason::MalformedFunctionCall => "MALFORMED_FUNCTION_CALL",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "FINISH_REASON_UNSPECIFIED" => Some(Self::Unspecified),
                "STOP" => Some(Self::Stop),
                "MAX_TOKENS" => Some(Self::MaxTokens),
                "SAFETY" => Some(Self::Safety),
                "RECITATION" => Some(Self::Recitation),
                "OTHER" => Some(Self::Other),
                "BLOCKLIST" => Some(Self::Blocklist),
                "PROHIBITED_CONTENT" => Some(Self::ProhibitedContent),
                "SPII" => Some(Self::Spii),
                "MALFORMED_FUNCTION_CALL" => Some(Self::MalformedFunctionCall),
                _ => None,
            }
        }
    }
}
/// Metadata returned to client when grounding is enabled.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GroundingMetadata {
    /// Optional. Web search queries for the following-up web search.
    #[prost(string, repeated, tag = "1")]
    pub web_search_queries: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. Google search entry for the following-up web searches.
    #[prost(message, optional, tag = "4")]
    pub search_entry_point: ::core::option::Option<SearchEntryPoint>,
}
/// Google search entry point.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SearchEntryPoint {
    /// Optional. Web content snippet that can be embedded in a web page or an app
    /// webview.
    #[prost(string, tag = "1")]
    pub rendered_content: ::prost::alloc::string::String,
    /// Optional. Base64 encoded JSON representing array of <search term, search
    /// url> tuple.
    #[prost(bytes = "vec", tag = "2")]
    pub sdk_blob: ::prost::alloc::vec::Vec<u8>,
}
/// Harm categories that will block the content.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum HarmCategory {
    /// The harm category is unspecified.
    Unspecified = 0,
    /// The harm category is hate speech.
    HateSpeech = 1,
    /// The harm category is dangerous content.
    DangerousContent = 2,
    /// The harm category is harassment.
    Harassment = 3,
    /// The harm category is sexually explicit content.
    SexuallyExplicit = 4,
}
impl HarmCategory {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            HarmCategory::Unspecified => "HARM_CATEGORY_UNSPECIFIED",
            HarmCategory::HateSpeech => "HARM_CATEGORY_HATE_SPEECH",
            HarmCategory::DangerousContent => "HARM_CATEGORY_DANGEROUS_CONTENT",
            HarmCategory::Harassment => "HARM_CATEGORY_HARASSMENT",
            HarmCategory::SexuallyExplicit => "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "HARM_CATEGORY_UNSPECIFIED" => Some(Self::Unspecified),
            "HARM_CATEGORY_HATE_SPEECH" => Some(Self::HateSpeech),
            "HARM_CATEGORY_DANGEROUS_CONTENT" => Some(Self::DangerousContent),
            "HARM_CATEGORY_HARASSMENT" => Some(Self::Harassment),
            "HARM_CATEGORY_SEXUALLY_EXPLICIT" => Some(Self::SexuallyExplicit),
            _ => None,
        }
    }
}
/// Metadata describing the Model's input and output for explanation.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplanationMetadata {
    /// Required. Map from feature names to feature input metadata. Keys are the
    /// name of the features. Values are the specification of the feature.
    ///
    /// An empty InputMetadata is valid. It describes a text feature which has the
    /// name specified as the key in
    /// [ExplanationMetadata.inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs].
    /// The baseline of the empty feature is chosen by Vertex AI.
    ///
    /// For Vertex AI-provided Tensorflow images, the key can be any friendly
    /// name of the feature. Once specified,
    /// [featureAttributions][google.cloud.aiplatform.v1.Attribution.feature_attributions]
    /// are keyed by this key (if not grouped with another feature).
    ///
    /// For custom images, the key must match with the key in
    /// [instance][google.cloud.aiplatform.v1.ExplainRequest.instances].
    #[prost(map = "string, message", tag = "1")]
    pub inputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        explanation_metadata::InputMetadata,
    >,
    /// Required. Map from output names to output metadata.
    ///
    /// For Vertex AI-provided Tensorflow images, keys can be any user defined
    /// string that consists of any UTF-8 characters.
    ///
    /// For custom images, keys are the name of the output field in the prediction
    /// to be explained.
    ///
    /// Currently only one key is allowed.
    #[prost(map = "string, message", tag = "2")]
    pub outputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        explanation_metadata::OutputMetadata,
    >,
    /// Points to a YAML file stored on Google Cloud Storage describing the format
    /// of the [feature
    /// attributions][google.cloud.aiplatform.v1.Attribution.feature_attributions].
    /// The schema is defined as an OpenAPI 3.0.2 [Schema
    /// Object](<https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject>).
    /// AutoML tabular Models always have this field populated by Vertex AI.
    /// Note: The URI given on output may be different, including the URI scheme,
    /// than the one given on input. The output URI will point to a location where
    /// the user only has a read access.
    #[prost(string, tag = "3")]
    pub feature_attributions_schema_uri: ::prost::alloc::string::String,
    /// Name of the source to generate embeddings for example based explanations.
    #[prost(string, tag = "5")]
    pub latent_space_source: ::prost::alloc::string::String,
}
/// Nested message and enum types in `ExplanationMetadata`.
pub mod explanation_metadata {
    /// Metadata of the input of a feature.
    ///
    /// Fields other than
    /// [InputMetadata.input_baselines][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.input_baselines]
    /// are applicable only for Models that are using Vertex AI-provided images for
    /// Tensorflow.
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct InputMetadata {
        /// Baseline inputs for this feature.
        ///
        /// If no baseline is specified, Vertex AI chooses the baseline for this
        /// feature. If multiple baselines are specified, Vertex AI returns the
        /// average attributions across them in
        /// [Attribution.feature_attributions][google.cloud.aiplatform.v1.Attribution.feature_attributions].
        ///
        /// For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape
        /// of each baseline must match the shape of the input tensor. If a scalar is
        /// provided, we broadcast to the same shape as the input tensor.
        ///
        /// For custom images, the element of the baselines must be in the same
        /// format as the feature's input in the
        /// [instance][google.cloud.aiplatform.v1.ExplainRequest.instances][]. The
        /// schema of any single instance may be specified via Endpoint's
        /// DeployedModels' [Model's][google.cloud.aiplatform.v1.DeployedModel.model]
        /// [PredictSchemata's][google.cloud.aiplatform.v1.Model.predict_schemata]
        /// [instance_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri].
        #[prost(message, repeated, tag = "1")]
        pub input_baselines: ::prost::alloc::vec::Vec<::prost_types::Value>,
        /// Name of the input tensor for this feature. Required and is only
        /// applicable to Vertex AI-provided images for Tensorflow.
        #[prost(string, tag = "2")]
        pub input_tensor_name: ::prost::alloc::string::String,
        /// Defines how the feature is encoded into the input tensor. Defaults to
        /// IDENTITY.
        #[prost(enumeration = "input_metadata::Encoding", tag = "3")]
        pub encoding: i32,
        /// Modality of the feature. Valid values are: numeric, image. Defaults to
        /// numeric.
        #[prost(string, tag = "4")]
        pub modality: ::prost::alloc::string::String,
        /// The domain details of the input feature value. Like min/max, original
        /// mean or standard deviation if normalized.
        #[prost(message, optional, tag = "5")]
        pub feature_value_domain: ::core::option::Option<
            input_metadata::FeatureValueDomain,
        >,
        /// Specifies the index of the values of the input tensor.
        /// Required when the input tensor is a sparse representation. Refer to
        /// Tensorflow documentation for more details:
        /// <https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.>
        #[prost(string, tag = "6")]
        pub indices_tensor_name: ::prost::alloc::string::String,
        /// Specifies the shape of the values of the input if the input is a sparse
        /// representation. Refer to Tensorflow documentation for more details:
        /// <https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.>
        #[prost(string, tag = "7")]
        pub dense_shape_tensor_name: ::prost::alloc::string::String,
        /// A list of feature names for each index in the input tensor.
        /// Required when the input
        /// [InputMetadata.encoding][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.encoding]
        /// is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
        #[prost(string, repeated, tag = "8")]
        pub index_feature_mapping: ::prost::alloc::vec::Vec<
            ::prost::alloc::string::String,
        >,
        /// Encoded tensor is a transformation of the input tensor. Must be provided
        /// if choosing
        /// [Integrated Gradients
        /// attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution]
        /// or [XRAI
        /// attribution][google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution]
        /// and the input tensor is not differentiable.
        ///
        /// An encoded tensor is generated if the input tensor is encoded by a lookup
        /// table.
        #[prost(string, tag = "9")]
        pub encoded_tensor_name: ::prost::alloc::string::String,
        /// A list of baselines for the encoded tensor.
        ///
        /// The shape of each baseline should match the shape of the encoded tensor.
        /// If a scalar is provided, Vertex AI broadcasts to the same shape as the
        /// encoded tensor.
        #[prost(message, repeated, tag = "10")]
        pub encoded_baselines: ::prost::alloc::vec::Vec<::prost_types::Value>,
        /// Visualization configurations for image explanation.
        #[prost(message, optional, tag = "11")]
        pub visualization: ::core::option::Option<input_metadata::Visualization>,
        /// Name of the group that the input belongs to. Features with the same group
        /// name will be treated as one feature when computing attributions. Features
        /// grouped together can have different shapes in value. If provided, there
        /// will be one single attribution generated in
        /// [Attribution.feature_attributions][google.cloud.aiplatform.v1.Attribution.feature_attributions],
        /// keyed by the group name.
        #[prost(string, tag = "12")]
        pub group_name: ::prost::alloc::string::String,
    }
    /// Nested message and enum types in `InputMetadata`.
    pub mod input_metadata {
        /// Domain details of the input feature value. Provides numeric information
        /// about the feature, such as its range (min, max). If the feature has been
        /// pre-processed, for example with z-scoring, then it provides information
        /// about how to recover the original feature. For example, if the input
        /// feature is an image and it has been pre-processed to obtain 0-mean and
        /// stddev = 1 values, then original_mean, and original_stddev refer to the
        /// mean and stddev of the original feature (e.g. image tensor) from which
        /// input feature (with mean = 0 and stddev = 1) was obtained.
        #[allow(clippy::derive_partial_eq_without_eq)]
        #[derive(Clone, Copy, PartialEq, ::prost::Message)]
        pub struct FeatureValueDomain {
            /// The minimum permissible value for this feature.
            #[prost(float, tag = "1")]
            pub min_value: f32,
            /// The maximum permissible value for this feature.
            #[prost(float, tag = "2")]
            pub max_value: f32,
            /// If this input feature has been normalized to a mean value of 0,
            /// the original_mean specifies the mean value of the domain prior to
            /// normalization.
            #[prost(float, tag = "3")]
            pub original_mean: f32,
            /// If this input feature has been normalized to a standard deviation of
            /// 1.0, the original_stddev specifies the standard deviation of the domain
            /// prior to normalization.
            #[prost(float, tag = "4")]
            pub original_stddev: f32,
        }
        /// Visualization configurations for image explanation.
        #[allow(clippy::derive_partial_eq_without_eq)]
        #[derive(Clone, Copy, PartialEq, ::prost::Message)]
        pub struct Visualization {
            /// Type of the image visualization. Only applicable to
            /// [Integrated Gradients
            /// attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution].
            /// OUTLINES shows regions of attribution, while PIXELS shows per-pixel
            /// attribution. Defaults to OUTLINES.
            #[prost(enumeration = "visualization::Type", tag = "1")]
            pub r#type: i32,
            /// Whether to only highlight pixels with positive contributions, negative
            /// or both. Defaults to POSITIVE.
            #[prost(enumeration = "visualization::Polarity", tag = "2")]
            pub polarity: i32,
            /// The color scheme used for the highlighted areas.
            ///
            /// Defaults to PINK_GREEN for
            /// [Integrated Gradients
            /// attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution],
            /// which shows positive attributions in green and negative in pink.
            ///
            /// Defaults to VIRIDIS for
            /// [XRAI
            /// attribution][google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution],
            /// which highlights the most influential regions in yellow and the least
            /// influential in blue.
            #[prost(enumeration = "visualization::ColorMap", tag = "3")]
            pub color_map: i32,
            /// Excludes attributions above the specified percentile from the
            /// highlighted areas. Using the clip_percent_upperbound and
            /// clip_percent_lowerbound together can be useful for filtering out noise
            /// and making it easier to see areas of strong attribution. Defaults to
            /// 99.9.
            #[prost(float, tag = "4")]
            pub clip_percent_upperbound: f32,
            /// Excludes attributions below the specified percentile, from the
            /// highlighted areas. Defaults to 62.
            #[prost(float, tag = "5")]
            pub clip_percent_lowerbound: f32,
            /// How the original image is displayed in the visualization.
            /// Adjusting the overlay can help increase visual clarity if the original
            /// image makes it difficult to view the visualization. Defaults to NONE.
            #[prost(enumeration = "visualization::OverlayType", tag = "6")]
            pub overlay_type: i32,
        }
        /// Nested message and enum types in `Visualization`.
        pub mod visualization {
            /// Type of the image visualization. Only applicable to
            /// [Integrated Gradients
            /// attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution].
            #[derive(
                Clone,
                Copy,
                Debug,
                PartialEq,
                Eq,
                Hash,
                PartialOrd,
                Ord,
                ::prost::Enumeration
            )]
            #[repr(i32)]
            pub enum Type {
                /// Should not be used.
                Unspecified = 0,
                /// Shows which pixel contributed to the image prediction.
                Pixels = 1,
                /// Shows which region contributed to the image prediction by outlining
                /// the region.
                Outlines = 2,
            }
            impl Type {
                /// String value of the enum field names used in the ProtoBuf definition.
                ///
                /// The values are not transformed in any way and thus are considered stable
                /// (if the ProtoBuf definition does not change) and safe for programmatic use.
                pub fn as_str_name(&self) -> &'static str {
                    match self {
                        Type::Unspecified => "TYPE_UNSPECIFIED",
                        Type::Pixels => "PIXELS",
                        Type::Outlines => "OUTLINES",
                    }
                }
                /// Creates an enum from field names used in the ProtoBuf definition.
                pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                    match value {
                        "TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                        "PIXELS" => Some(Self::Pixels),
                        "OUTLINES" => Some(Self::Outlines),
                        _ => None,
                    }
                }
            }
            /// Whether to only highlight pixels with positive contributions, negative
            /// or both. Defaults to POSITIVE.
            #[derive(
                Clone,
                Copy,
                Debug,
                PartialEq,
                Eq,
                Hash,
                PartialOrd,
                Ord,
                ::prost::Enumeration
            )]
            #[repr(i32)]
            pub enum Polarity {
                /// Default value. This is the same as POSITIVE.
                Unspecified = 0,
                /// Highlights the pixels/outlines that were most influential to the
                /// model's prediction.
                Positive = 1,
                /// Setting polarity to negative highlights areas that does not lead to
                /// the models's current prediction.
                Negative = 2,
                /// Shows both positive and negative attributions.
                Both = 3,
            }
            impl Polarity {
                /// String value of the enum field names used in the ProtoBuf definition.
                ///
                /// The values are not transformed in any way and thus are considered stable
                /// (if the ProtoBuf definition does not change) and safe for programmatic use.
                pub fn as_str_name(&self) -> &'static str {
                    match self {
                        Polarity::Unspecified => "POLARITY_UNSPECIFIED",
                        Polarity::Positive => "POSITIVE",
                        Polarity::Negative => "NEGATIVE",
                        Polarity::Both => "BOTH",
                    }
                }
                /// Creates an enum from field names used in the ProtoBuf definition.
                pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                    match value {
                        "POLARITY_UNSPECIFIED" => Some(Self::Unspecified),
                        "POSITIVE" => Some(Self::Positive),
                        "NEGATIVE" => Some(Self::Negative),
                        "BOTH" => Some(Self::Both),
                        _ => None,
                    }
                }
            }
            /// The color scheme used for highlighting areas.
            #[derive(
                Clone,
                Copy,
                Debug,
                PartialEq,
                Eq,
                Hash,
                PartialOrd,
                Ord,
                ::prost::Enumeration
            )]
            #[repr(i32)]
            pub enum ColorMap {
                /// Should not be used.
                Unspecified = 0,
                /// Positive: green. Negative: pink.
                PinkGreen = 1,
                /// Viridis color map: A perceptually uniform color mapping which is
                /// easier to see by those with colorblindness and progresses from yellow
                /// to green to blue. Positive: yellow. Negative: blue.
                Viridis = 2,
                /// Positive: red. Negative: red.
                Red = 3,
                /// Positive: green. Negative: green.
                Green = 4,
                /// Positive: green. Negative: red.
                RedGreen = 6,
                /// PiYG palette.
                PinkWhiteGreen = 5,
            }
            impl ColorMap {
                /// String value of the enum field names used in the ProtoBuf definition.
                ///
                /// The values are not transformed in any way and thus are considered stable
                /// (if the ProtoBuf definition does not change) and safe for programmatic use.
                pub fn as_str_name(&self) -> &'static str {
                    match self {
                        ColorMap::Unspecified => "COLOR_MAP_UNSPECIFIED",
                        ColorMap::PinkGreen => "PINK_GREEN",
                        ColorMap::Viridis => "VIRIDIS",
                        ColorMap::Red => "RED",
                        ColorMap::Green => "GREEN",
                        ColorMap::RedGreen => "RED_GREEN",
                        ColorMap::PinkWhiteGreen => "PINK_WHITE_GREEN",
                    }
                }
                /// Creates an enum from field names used in the ProtoBuf definition.
                pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                    match value {
                        "COLOR_MAP_UNSPECIFIED" => Some(Self::Unspecified),
                        "PINK_GREEN" => Some(Self::PinkGreen),
                        "VIRIDIS" => Some(Self::Viridis),
                        "RED" => Some(Self::Red),
                        "GREEN" => Some(Self::Green),
                        "RED_GREEN" => Some(Self::RedGreen),
                        "PINK_WHITE_GREEN" => Some(Self::PinkWhiteGreen),
                        _ => None,
                    }
                }
            }
            /// How the original image is displayed in the visualization.
            #[derive(
                Clone,
                Copy,
                Debug,
                PartialEq,
                Eq,
                Hash,
                PartialOrd,
                Ord,
                ::prost::Enumeration
            )]
            #[repr(i32)]
            pub enum OverlayType {
                /// Default value. This is the same as NONE.
                Unspecified = 0,
                /// No overlay.
                None = 1,
                /// The attributions are shown on top of the original image.
                Original = 2,
                /// The attributions are shown on top of grayscaled version of the
                /// original image.
                Grayscale = 3,
                /// The attributions are used as a mask to reveal predictive parts of
                /// the image and hide the un-predictive parts.
                MaskBlack = 4,
            }
            impl OverlayType {
                /// String value of the enum field names used in the ProtoBuf definition.
                ///
                /// The values are not transformed in any way and thus are considered stable
                /// (if the ProtoBuf definition does not change) and safe for programmatic use.
                pub fn as_str_name(&self) -> &'static str {
                    match self {
                        OverlayType::Unspecified => "OVERLAY_TYPE_UNSPECIFIED",
                        OverlayType::None => "NONE",
                        OverlayType::Original => "ORIGINAL",
                        OverlayType::Grayscale => "GRAYSCALE",
                        OverlayType::MaskBlack => "MASK_BLACK",
                    }
                }
                /// Creates an enum from field names used in the ProtoBuf definition.
                pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                    match value {
                        "OVERLAY_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                        "NONE" => Some(Self::None),
                        "ORIGINAL" => Some(Self::Original),
                        "GRAYSCALE" => Some(Self::Grayscale),
                        "MASK_BLACK" => Some(Self::MaskBlack),
                        _ => None,
                    }
                }
            }
        }
        /// Defines how a feature is encoded. Defaults to IDENTITY.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum Encoding {
            /// Default value. This is the same as IDENTITY.
            Unspecified = 0,
            /// The tensor represents one feature.
            Identity = 1,
            /// The tensor represents a bag of features where each index maps to
            /// a feature.
            /// [InputMetadata.index_feature_mapping][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.index_feature_mapping]
            /// must be provided for this encoding. For example:
            /// ```
            /// input = \[27, 6.0, 150\]
            /// index_feature_mapping = \["age", "height", "weight"\]
            /// ```
            BagOfFeatures = 2,
            /// The tensor represents a bag of features where each index maps to a
            /// feature. Zero values in the tensor indicates feature being
            /// non-existent.
            /// [InputMetadata.index_feature_mapping][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.index_feature_mapping]
            /// must be provided for this encoding. For example:
            /// ```
            /// input = \[2, 0, 5, 0, 1\]
            /// index_feature_mapping = \["a", "b", "c", "d", "e"\]
            /// ```
            BagOfFeaturesSparse = 3,
            /// The tensor is a list of binaries representing whether a feature exists
            /// or not (1 indicates existence).
            /// [InputMetadata.index_feature_mapping][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.index_feature_mapping]
            /// must be provided for this encoding. For example:
            /// ```
            /// input = \[1, 0, 1, 0, 1\]
            /// index_feature_mapping = \["a", "b", "c", "d", "e"\]
            /// ```
            Indicator = 4,
            /// The tensor is encoded into a 1-dimensional array represented by an
            /// encoded tensor.
            /// [InputMetadata.encoded_tensor_name][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.encoded_tensor_name]
            /// must be provided for this encoding. For example:
            /// ```
            /// input = \["This", "is", "a", "test", "."\]
            /// encoded = \[0.1, 0.2, 0.3, 0.4, 0.5\]
            /// ```
            CombinedEmbedding = 5,
            /// Select this encoding when the input tensor is encoded into a
            /// 2-dimensional array represented by an encoded tensor.
            /// [InputMetadata.encoded_tensor_name][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.encoded_tensor_name]
            /// must be provided for this encoding. The first dimension of the encoded
            /// tensor's shape is the same as the input tensor's shape. For example:
            /// ```
            /// input = \["This", "is", "a", "test", "."\]
            /// encoded = \[[0.1, 0.2, 0.3, 0.4, 0.5\],
            ///             \[0.2, 0.1, 0.4, 0.3, 0.5\],
            ///             \[0.5, 0.1, 0.3, 0.5, 0.4\],
            ///             \[0.5, 0.3, 0.1, 0.2, 0.4\],
            ///             \[0.4, 0.3, 0.2, 0.5, 0.1]\]
            /// ```
            ConcatEmbedding = 6,
        }
        impl Encoding {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Encoding::Unspecified => "ENCODING_UNSPECIFIED",
                    Encoding::Identity => "IDENTITY",
                    Encoding::BagOfFeatures => "BAG_OF_FEATURES",
                    Encoding::BagOfFeaturesSparse => "BAG_OF_FEATURES_SPARSE",
                    Encoding::Indicator => "INDICATOR",
                    Encoding::CombinedEmbedding => "COMBINED_EMBEDDING",
                    Encoding::ConcatEmbedding => "CONCAT_EMBEDDING",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "ENCODING_UNSPECIFIED" => Some(Self::Unspecified),
                    "IDENTITY" => Some(Self::Identity),
                    "BAG_OF_FEATURES" => Some(Self::BagOfFeatures),
                    "BAG_OF_FEATURES_SPARSE" => Some(Self::BagOfFeaturesSparse),
                    "INDICATOR" => Some(Self::Indicator),
                    "COMBINED_EMBEDDING" => Some(Self::CombinedEmbedding),
                    "CONCAT_EMBEDDING" => Some(Self::ConcatEmbedding),
                    _ => None,
                }
            }
        }
    }
    /// Metadata of the prediction output to be explained.
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct OutputMetadata {
        /// Name of the output tensor. Required and is only applicable to Vertex
        /// AI provided images for Tensorflow.
        #[prost(string, tag = "3")]
        pub output_tensor_name: ::prost::alloc::string::String,
        /// Defines how to map
        /// [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
        /// to
        /// [Attribution.output_display_name][google.cloud.aiplatform.v1.Attribution.output_display_name].
        ///
        /// If neither of the fields are specified,
        /// [Attribution.output_display_name][google.cloud.aiplatform.v1.Attribution.output_display_name]
        /// will not be populated.
        #[prost(oneof = "output_metadata::DisplayNameMapping", tags = "1, 2")]
        pub display_name_mapping: ::core::option::Option<
            output_metadata::DisplayNameMapping,
        >,
    }
    /// Nested message and enum types in `OutputMetadata`.
    pub mod output_metadata {
        /// Defines how to map
        /// [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
        /// to
        /// [Attribution.output_display_name][google.cloud.aiplatform.v1.Attribution.output_display_name].
        ///
        /// If neither of the fields are specified,
        /// [Attribution.output_display_name][google.cloud.aiplatform.v1.Attribution.output_display_name]
        /// will not be populated.
        #[allow(clippy::derive_partial_eq_without_eq)]
        #[derive(Clone, PartialEq, ::prost::Oneof)]
        pub enum DisplayNameMapping {
            /// Static mapping between the index and display name.
            ///
            /// Use this if the outputs are a deterministic n-dimensional array, e.g. a
            /// list of scores of all the classes in a pre-defined order for a
            /// multi-classification Model. It's not feasible if the outputs are
            /// non-deterministic, e.g. the Model produces top-k classes or sort the
            /// outputs by their values.
            ///
            /// The shape of the value must be an n-dimensional array of strings. The
            /// number of dimensions must match that of the outputs to be explained.
            /// The
            /// [Attribution.output_display_name][google.cloud.aiplatform.v1.Attribution.output_display_name]
            /// is populated by locating in the mapping with
            /// [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index].
            #[prost(message, tag = "1")]
            IndexDisplayNameMapping(::prost_types::Value),
            /// Specify a field name in the prediction to look for the display name.
            ///
            /// Use this if the prediction contains the display names for the outputs.
            ///
            /// The display names in the prediction must have the same shape of the
            /// outputs, so that it can be located by
            /// [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
            /// for a specific output.
            #[prost(string, tag = "2")]
            DisplayNameMappingKey(::prost::alloc::string::String),
        }
    }
}
/// The storage details for Avro input content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AvroSource {
    /// Required. Google Cloud Storage location.
    #[prost(message, optional, tag = "1")]
    pub gcs_source: ::core::option::Option<GcsSource>,
}
/// The storage details for CSV input content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CsvSource {
    /// Required. Google Cloud Storage location.
    #[prost(message, optional, tag = "1")]
    pub gcs_source: ::core::option::Option<GcsSource>,
}
/// The Google Cloud Storage location for the input content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GcsSource {
    /// Required. Google Cloud Storage URI(-s) to the input file(s). May contain
    /// wildcards. For more information on wildcards, see
    /// <https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.>
    #[prost(string, repeated, tag = "1")]
    pub uris: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// The Google Cloud Storage location where the output is to be written to.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GcsDestination {
    /// Required. Google Cloud Storage URI to output directory. If the uri doesn't
    /// end with
    /// '/', a '/' will be automatically appended. The directory is created if it
    /// doesn't exist.
    #[prost(string, tag = "1")]
    pub output_uri_prefix: ::prost::alloc::string::String,
}
/// The BigQuery location for the input content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BigQuerySource {
    /// Required. BigQuery URI to a table, up to 2000 characters long.
    /// Accepted forms:
    ///
    /// *  BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
    #[prost(string, tag = "1")]
    pub input_uri: ::prost::alloc::string::String,
}
/// The BigQuery location for the output content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BigQueryDestination {
    /// Required. BigQuery URI to a project or table, up to 2000 characters long.
    ///
    /// When only the project is specified, the Dataset and Table is created.
    /// When the full table reference is specified, the Dataset must exist and
    /// table must not exist.
    ///
    /// Accepted forms:
    ///
    /// *  BigQuery path. For example:
    /// `bq://projectId` or `bq://projectId.bqDatasetId` or
    /// `bq://projectId.bqDatasetId.bqTableId`.
    #[prost(string, tag = "1")]
    pub output_uri: ::prost::alloc::string::String,
}
/// The storage details for CSV output content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CsvDestination {
    /// Required. Google Cloud Storage location.
    #[prost(message, optional, tag = "1")]
    pub gcs_destination: ::core::option::Option<GcsDestination>,
}
/// The storage details for TFRecord output content.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct TfRecordDestination {
    /// Required. Google Cloud Storage location.
    #[prost(message, optional, tag = "1")]
    pub gcs_destination: ::core::option::Option<GcsDestination>,
}
/// The Container Registry location for the container image.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ContainerRegistryDestination {
    /// Required. Container Registry URI of a container image.
    /// Only Google Container Registry and Artifact Registry are supported now.
    /// Accepted forms:
    ///
    /// *  Google Container Registry path. For example:
    ///     `gcr.io/projectId/imageName:tag`.
    ///
    /// *  Artifact Registry path. For example:
    ///     `us-central1-docker.pkg.dev/projectId/repoName/imageName:tag`.
    ///
    /// If a tag is not specified, "latest" will be used as the default tag.
    #[prost(string, tag = "1")]
    pub output_uri: ::prost::alloc::string::String,
}
/// Explanation of a prediction (provided in
/// [PredictResponse.predictions][google.cloud.aiplatform.v1.PredictResponse.predictions])
/// produced by the Model on a given
/// [instance][google.cloud.aiplatform.v1.ExplainRequest.instances].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Explanation {
    /// Output only. Feature attributions grouped by predicted outputs.
    ///
    /// For Models that predict only one output, such as regression Models that
    /// predict only one score, there is only one attibution that explains the
    /// predicted output. For Models that predict multiple outputs, such as
    /// multiclass Models that predict multiple classes, each element explains one
    /// specific item.
    /// [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
    /// can be used to identify which output this attribution is explaining.
    ///
    /// By default, we provide Shapley values for the predicted class. However,
    /// you can configure the explanation request to generate Shapley values for
    /// any other classes too. For example, if a model predicts a probability of
    /// `0.4` for approving a loan application, the model's decision is to reject
    /// the application since `p(reject) = 0.6 > p(approve) = 0.4`, and the default
    /// Shapley values would be computed for rejection decision and not approval,
    /// even though the latter might be the positive class.
    ///
    /// If users set
    /// [ExplanationParameters.top_k][google.cloud.aiplatform.v1.ExplanationParameters.top_k],
    /// the attributions are sorted by
    /// [instance_output_value][Attributions.instance_output_value] in descending
    /// order. If
    /// [ExplanationParameters.output_indices][google.cloud.aiplatform.v1.ExplanationParameters.output_indices]
    /// is specified, the attributions are stored by
    /// [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
    /// in the same order as they appear in the output_indices.
    #[prost(message, repeated, tag = "1")]
    pub attributions: ::prost::alloc::vec::Vec<Attribution>,
    /// Output only. List of the nearest neighbors for example-based explanations.
    ///
    /// For models deployed with the examples explanations feature enabled, the
    /// attributions field is empty and instead the neighbors field is populated.
    #[prost(message, repeated, tag = "2")]
    pub neighbors: ::prost::alloc::vec::Vec<Neighbor>,
}
/// Aggregated explanation metrics for a Model over a set of instances.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ModelExplanation {
    /// Output only. Aggregated attributions explaining the Model's prediction
    /// outputs over the set of instances. The attributions are grouped by outputs.
    ///
    /// For Models that predict only one output, such as regression Models that
    /// predict only one score, there is only one attibution that explains the
    /// predicted output. For Models that predict multiple outputs, such as
    /// multiclass Models that predict multiple classes, each element explains one
    /// specific item.
    /// [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
    /// can be used to identify which output this attribution is explaining.
    ///
    /// The
    /// [baselineOutputValue][google.cloud.aiplatform.v1.Attribution.baseline_output_value],
    /// [instanceOutputValue][google.cloud.aiplatform.v1.Attribution.instance_output_value]
    /// and
    /// [featureAttributions][google.cloud.aiplatform.v1.Attribution.feature_attributions]
    /// fields are averaged over the test data.
    ///
    /// NOTE: Currently AutoML tabular classification Models produce only one
    /// attribution, which averages attributions over all the classes it predicts.
    /// [Attribution.approximation_error][google.cloud.aiplatform.v1.Attribution.approximation_error]
    /// is not populated.
    #[prost(message, repeated, tag = "1")]
    pub mean_attributions: ::prost::alloc::vec::Vec<Attribution>,
}
/// Attribution that explains a particular prediction output.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Attribution {
    /// Output only. Model predicted output if the input instance is constructed
    /// from the baselines of all the features defined in
    /// [ExplanationMetadata.inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs].
    /// The field name of the output is determined by the key in
    /// [ExplanationMetadata.outputs][google.cloud.aiplatform.v1.ExplanationMetadata.outputs].
    ///
    /// If the Model's predicted output has multiple dimensions (rank > 1), this is
    /// the value in the output located by
    /// [output_index][google.cloud.aiplatform.v1.Attribution.output_index].
    ///
    /// If there are multiple baselines, their output values are averaged.
    #[prost(double, tag = "1")]
    pub baseline_output_value: f64,
    /// Output only. Model predicted output on the corresponding [explanation
    /// instance][ExplainRequest.instances]. The field name of the output is
    /// determined by the key in
    /// [ExplanationMetadata.outputs][google.cloud.aiplatform.v1.ExplanationMetadata.outputs].
    ///
    /// If the Model predicted output has multiple dimensions, this is the value in
    /// the output located by
    /// [output_index][google.cloud.aiplatform.v1.Attribution.output_index].
    #[prost(double, tag = "2")]
    pub instance_output_value: f64,
    /// Output only. Attributions of each explained feature. Features are extracted
    /// from the [prediction
    /// instances][google.cloud.aiplatform.v1.ExplainRequest.instances] according
    /// to [explanation metadata for
    /// inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs].
    ///
    /// The value is a struct, whose keys are the name of the feature. The values
    /// are how much the feature in the
    /// [instance][google.cloud.aiplatform.v1.ExplainRequest.instances] contributed
    /// to the predicted result.
    ///
    /// The format of the value is determined by the feature's input format:
    ///
    ///    * If the feature is a scalar value, the attribution value is a
    ///      [floating number][google.protobuf.Value.number_value].
    ///
    ///    * If the feature is an array of scalar values, the attribution value is
    ///      an [array][google.protobuf.Value.list_value].
    ///
    ///    * If the feature is a struct, the attribution value is a
    ///      [struct][google.protobuf.Value.struct_value]. The keys in the
    ///      attribution value struct are the same as the keys in the feature
    ///      struct. The formats of the values in the attribution struct are
    ///      determined by the formats of the values in the feature struct.
    ///
    /// The
    /// [ExplanationMetadata.feature_attributions_schema_uri][google.cloud.aiplatform.v1.ExplanationMetadata.feature_attributions_schema_uri]
    /// field, pointed to by the
    /// [ExplanationSpec][google.cloud.aiplatform.v1.ExplanationSpec] field of the
    /// [Endpoint.deployed_models][google.cloud.aiplatform.v1.Endpoint.deployed_models]
    /// object, points to the schema file that describes the features and their
    /// attribution values (if it is populated).
    #[prost(message, optional, tag = "3")]
    pub feature_attributions: ::core::option::Option<::prost_types::Value>,
    /// Output only. The index that locates the explained prediction output.
    ///
    /// If the prediction output is a scalar value, output_index is not populated.
    /// If the prediction output has multiple dimensions, the length of the
    /// output_index list is the same as the number of dimensions of the output.
    /// The i-th element in output_index is the element index of the i-th dimension
    /// of the output vector. Indices start from 0.
    #[prost(int32, repeated, packed = "false", tag = "4")]
    pub output_index: ::prost::alloc::vec::Vec<i32>,
    /// Output only. The display name of the output identified by
    /// [output_index][google.cloud.aiplatform.v1.Attribution.output_index]. For
    /// example, the predicted class name by a multi-classification Model.
    ///
    /// This field is only populated iff the Model predicts display names as a
    /// separate field along with the explained output. The predicted display name
    /// must has the same shape of the explained output, and can be located using
    /// output_index.
    #[prost(string, tag = "5")]
    pub output_display_name: ::prost::alloc::string::String,
    /// Output only. Error of
    /// [feature_attributions][google.cloud.aiplatform.v1.Attribution.feature_attributions]
    /// caused by approximation used in the explanation method. Lower value means
    /// more precise attributions.
    ///
    /// * For Sampled Shapley
    /// [attribution][google.cloud.aiplatform.v1.ExplanationParameters.sampled_shapley_attribution],
    /// increasing
    /// [path_count][google.cloud.aiplatform.v1.SampledShapleyAttribution.path_count]
    /// might reduce the error.
    /// * For Integrated Gradients
    /// [attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution],
    /// increasing
    /// [step_count][google.cloud.aiplatform.v1.IntegratedGradientsAttribution.step_count]
    /// might reduce the error.
    /// * For [XRAI
    /// attribution][google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution],
    /// increasing
    /// [step_count][google.cloud.aiplatform.v1.XraiAttribution.step_count] might
    /// reduce the error.
    ///
    /// See [this introduction](/vertex-ai/docs/explainable-ai/overview)
    /// for more information.
    #[prost(double, tag = "6")]
    pub approximation_error: f64,
    /// Output only. Name of the explain output. Specified as the key in
    /// [ExplanationMetadata.outputs][google.cloud.aiplatform.v1.ExplanationMetadata.outputs].
    #[prost(string, tag = "7")]
    pub output_name: ::prost::alloc::string::String,
}
/// Neighbors for example-based explanations.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Neighbor {
    /// Output only. The neighbor id.
    #[prost(string, tag = "1")]
    pub neighbor_id: ::prost::alloc::string::String,
    /// Output only. The neighbor distance.
    #[prost(double, tag = "2")]
    pub neighbor_distance: f64,
}
/// Specification of Model explanation.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplanationSpec {
    /// Required. Parameters that configure explaining of the Model's predictions.
    #[prost(message, optional, tag = "1")]
    pub parameters: ::core::option::Option<ExplanationParameters>,
    /// Optional. Metadata describing the Model's input and output for explanation.
    #[prost(message, optional, tag = "2")]
    pub metadata: ::core::option::Option<ExplanationMetadata>,
}
/// Parameters to configure explaining for Model's predictions.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplanationParameters {
    /// If populated, returns attributions for top K indices of outputs
    /// (defaults to 1). Only applies to Models that predicts more than one outputs
    /// (e,g, multi-class Models). When set to -1, returns explanations for all
    /// outputs.
    #[prost(int32, tag = "4")]
    pub top_k: i32,
    /// If populated, only returns attributions that have
    /// [output_index][google.cloud.aiplatform.v1.Attribution.output_index]
    /// contained in output_indices. It must be an ndarray of integers, with the
    /// same shape of the output it's explaining.
    ///
    /// If not populated, returns attributions for
    /// [top_k][google.cloud.aiplatform.v1.ExplanationParameters.top_k] indices of
    /// outputs. If neither top_k nor output_indices is populated, returns the
    /// argmax index of the outputs.
    ///
    /// Only applicable to Models that predict multiple outputs (e,g, multi-class
    /// Models that predict multiple classes).
    #[prost(message, optional, tag = "5")]
    pub output_indices: ::core::option::Option<::prost_types::ListValue>,
    #[prost(oneof = "explanation_parameters::Method", tags = "1, 2, 3, 7")]
    pub method: ::core::option::Option<explanation_parameters::Method>,
}
/// Nested message and enum types in `ExplanationParameters`.
pub mod explanation_parameters {
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Method {
        /// An attribution method that approximates Shapley values for features that
        /// contribute to the label being predicted. A sampling strategy is used to
        /// approximate the value rather than considering all subsets of features.
        /// Refer to this paper for model details: <https://arxiv.org/abs/1306.4265.>
        #[prost(message, tag = "1")]
        SampledShapleyAttribution(super::SampledShapleyAttribution),
        /// An attribution method that computes Aumann-Shapley values taking
        /// advantage of the model's fully differentiable structure. Refer to this
        /// paper for more details: <https://arxiv.org/abs/1703.01365>
        #[prost(message, tag = "2")]
        IntegratedGradientsAttribution(super::IntegratedGradientsAttribution),
        /// An attribution method that redistributes Integrated Gradients
        /// attribution to segmented regions, taking advantage of the model's fully
        /// differentiable structure. Refer to this paper for
        /// more details: <https://arxiv.org/abs/1906.02825>
        ///
        /// XRAI currently performs better on natural images, like a picture of a
        /// house or an animal. If the images are taken in artificial environments,
        /// like a lab or manufacturing line, or from diagnostic equipment, like
        /// x-rays or quality-control cameras, use Integrated Gradients instead.
        #[prost(message, tag = "3")]
        XraiAttribution(super::XraiAttribution),
        /// Example-based explanations that returns the nearest neighbors from the
        /// provided dataset.
        #[prost(message, tag = "7")]
        Examples(super::Examples),
    }
}
/// An attribution method that approximates Shapley values for features that
/// contribute to the label being predicted. A sampling strategy is used to
/// approximate the value rather than considering all subsets of features.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct SampledShapleyAttribution {
    /// Required. The number of feature permutations to consider when approximating
    /// the Shapley values.
    ///
    /// Valid range of its value is \[1, 50\], inclusively.
    #[prost(int32, tag = "1")]
    pub path_count: i32,
}
/// An attribution method that computes the Aumann-Shapley value taking advantage
/// of the model's fully differentiable structure. Refer to this paper for
/// more details: <https://arxiv.org/abs/1703.01365>
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct IntegratedGradientsAttribution {
    /// Required. The number of steps for approximating the path integral.
    /// A good value to start is 50 and gradually increase until the
    /// sum to diff property is within the desired error range.
    ///
    /// Valid range of its value is \[1, 100\], inclusively.
    #[prost(int32, tag = "1")]
    pub step_count: i32,
    /// Config for SmoothGrad approximation of gradients.
    ///
    /// When enabled, the gradients are approximated by averaging the gradients
    /// from noisy samples in the vicinity of the inputs. Adding
    /// noise can help improve the computed gradients. Refer to this paper for more
    /// details: <https://arxiv.org/pdf/1706.03825.pdf>
    #[prost(message, optional, tag = "2")]
    pub smooth_grad_config: ::core::option::Option<SmoothGradConfig>,
    /// Config for IG with blur baseline.
    ///
    /// When enabled, a linear path from the maximally blurred image to the input
    /// image is created. Using a blurred baseline instead of zero (black image) is
    /// motivated by the BlurIG approach explained here:
    /// <https://arxiv.org/abs/2004.03383>
    #[prost(message, optional, tag = "3")]
    pub blur_baseline_config: ::core::option::Option<BlurBaselineConfig>,
}
/// An explanation method that redistributes Integrated Gradients
/// attributions to segmented regions, taking advantage of the model's fully
/// differentiable structure. Refer to this paper for more details:
/// <https://arxiv.org/abs/1906.02825>
///
/// Supported only by image Models.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct XraiAttribution {
    /// Required. The number of steps for approximating the path integral.
    /// A good value to start is 50 and gradually increase until the
    /// sum to diff property is met within the desired error range.
    ///
    /// Valid range of its value is \[1, 100\], inclusively.
    #[prost(int32, tag = "1")]
    pub step_count: i32,
    /// Config for SmoothGrad approximation of gradients.
    ///
    /// When enabled, the gradients are approximated by averaging the gradients
    /// from noisy samples in the vicinity of the inputs. Adding
    /// noise can help improve the computed gradients. Refer to this paper for more
    /// details: <https://arxiv.org/pdf/1706.03825.pdf>
    #[prost(message, optional, tag = "2")]
    pub smooth_grad_config: ::core::option::Option<SmoothGradConfig>,
    /// Config for XRAI with blur baseline.
    ///
    /// When enabled, a linear path from the maximally blurred image to the input
    /// image is created. Using a blurred baseline instead of zero (black image) is
    /// motivated by the BlurIG approach explained here:
    /// <https://arxiv.org/abs/2004.03383>
    #[prost(message, optional, tag = "3")]
    pub blur_baseline_config: ::core::option::Option<BlurBaselineConfig>,
}
/// Config for SmoothGrad approximation of gradients.
///
/// When enabled, the gradients are approximated by averaging the gradients from
/// noisy samples in the vicinity of the inputs. Adding noise can help improve
/// the computed gradients. Refer to this paper for more details:
/// <https://arxiv.org/pdf/1706.03825.pdf>
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SmoothGradConfig {
    /// The number of gradient samples to use for
    /// approximation. The higher this number, the more accurate the gradient
    /// is, but the runtime complexity increases by this factor as well.
    /// Valid range of its value is \[1, 50\]. Defaults to 3.
    #[prost(int32, tag = "3")]
    pub noisy_sample_count: i32,
    /// Represents the standard deviation of the gaussian kernel
    /// that will be used to add noise to the interpolated inputs
    /// prior to computing gradients.
    #[prost(oneof = "smooth_grad_config::GradientNoiseSigma", tags = "1, 2")]
    pub gradient_noise_sigma: ::core::option::Option<
        smooth_grad_config::GradientNoiseSigma,
    >,
}
/// Nested message and enum types in `SmoothGradConfig`.
pub mod smooth_grad_config {
    /// Represents the standard deviation of the gaussian kernel
    /// that will be used to add noise to the interpolated inputs
    /// prior to computing gradients.
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum GradientNoiseSigma {
        /// This is a single float value and will be used to add noise to all the
        /// features. Use this field when all features are normalized to have the
        /// same distribution: scale to range \[0, 1\], \[-1, 1\] or z-scoring, where
        /// features are normalized to have 0-mean and 1-variance. Learn more about
        /// [normalization](<https://developers.google.com/machine-learning/data-prep/transform/normalization>).
        ///
        /// For best results the recommended value is about 10% - 20% of the standard
        /// deviation of the input feature. Refer to section 3.2 of the SmoothGrad
        /// paper: <https://arxiv.org/pdf/1706.03825.pdf.> Defaults to 0.1.
        ///
        /// If the distribution is different per feature, set
        /// [feature_noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.feature_noise_sigma]
        /// instead for each feature.
        #[prost(float, tag = "1")]
        NoiseSigma(f32),
        /// This is similar to
        /// [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma],
        /// but provides additional flexibility. A separate noise sigma can be
        /// provided for each feature, which is useful if their distributions are
        /// different. No noise is added to features that are not set. If this field
        /// is unset,
        /// [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma]
        /// will be used for all features.
        #[prost(message, tag = "2")]
        FeatureNoiseSigma(super::FeatureNoiseSigma),
    }
}
/// Noise sigma by features. Noise sigma represents the standard deviation of the
/// gaussian kernel that will be used to add noise to interpolated inputs prior
/// to computing gradients.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FeatureNoiseSigma {
    /// Noise sigma per feature. No noise is added to features that are not set.
    #[prost(message, repeated, tag = "1")]
    pub noise_sigma: ::prost::alloc::vec::Vec<feature_noise_sigma::NoiseSigmaForFeature>,
}
/// Nested message and enum types in `FeatureNoiseSigma`.
pub mod feature_noise_sigma {
    /// Noise sigma for a single feature.
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct NoiseSigmaForFeature {
        /// The name of the input feature for which noise sigma is provided. The
        /// features are defined in
        /// [explanation metadata
        /// inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs].
        #[prost(string, tag = "1")]
        pub name: ::prost::alloc::string::String,
        /// This represents the standard deviation of the Gaussian kernel that will
        /// be used to add noise to the feature prior to computing gradients. Similar
        /// to [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma]
        /// but represents the noise added to the current feature. Defaults to 0.1.
        #[prost(float, tag = "2")]
        pub sigma: f32,
    }
}
/// Config for blur baseline.
///
/// When enabled, a linear path from the maximally blurred image to the input
/// image is created. Using a blurred baseline instead of zero (black image) is
/// motivated by the BlurIG approach explained here:
/// <https://arxiv.org/abs/2004.03383>
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct BlurBaselineConfig {
    /// The standard deviation of the blur kernel for the blurred baseline. The
    /// same blurring parameter is used for both the height and the width
    /// dimension. If not set, the method defaults to the zero (i.e. black for
    /// images) baseline.
    #[prost(float, tag = "1")]
    pub max_blur_sigma: f32,
}
/// Example-based explainability that returns the nearest neighbors from the
/// provided dataset.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Examples {
    /// The number of neighbors to return when querying for examples.
    #[prost(int32, tag = "3")]
    pub neighbor_count: i32,
    #[prost(oneof = "examples::Source", tags = "5")]
    pub source: ::core::option::Option<examples::Source>,
    #[prost(oneof = "examples::Config", tags = "2, 4")]
    pub config: ::core::option::Option<examples::Config>,
}
/// Nested message and enum types in `Examples`.
pub mod examples {
    /// The Cloud Storage input instances.
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct ExampleGcsSource {
        /// The format in which instances are given, if not specified, assume it's
        /// JSONL format. Currently only JSONL format is supported.
        #[prost(enumeration = "example_gcs_source::DataFormat", tag = "1")]
        pub data_format: i32,
        /// The Cloud Storage location for the input instances.
        #[prost(message, optional, tag = "2")]
        pub gcs_source: ::core::option::Option<super::GcsSource>,
    }
    /// Nested message and enum types in `ExampleGcsSource`.
    pub mod example_gcs_source {
        /// The format of the input example instances.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum DataFormat {
            /// Format unspecified, used when unset.
            Unspecified = 0,
            /// Examples are stored in JSONL files.
            Jsonl = 1,
        }
        impl DataFormat {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    DataFormat::Unspecified => "DATA_FORMAT_UNSPECIFIED",
                    DataFormat::Jsonl => "JSONL",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "DATA_FORMAT_UNSPECIFIED" => Some(Self::Unspecified),
                    "JSONL" => Some(Self::Jsonl),
                    _ => None,
                }
            }
        }
    }
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Source {
        /// The Cloud Storage input instances.
        #[prost(message, tag = "5")]
        ExampleGcsSource(ExampleGcsSource),
    }
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Config {
        /// The full configuration for the generated index, the semantics are the
        /// same as [metadata][google.cloud.aiplatform.v1.Index.metadata] and should
        /// match
        /// [NearestNeighborSearchConfig](<https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config>).
        #[prost(message, tag = "2")]
        NearestNeighborSearchConfig(::prost_types::Value),
        /// Simplified preset configuration, which automatically sets configuration
        /// values based on the desired query speed-precision trade-off and modality.
        #[prost(message, tag = "4")]
        Presets(super::Presets),
    }
}
/// Preset configuration for example-based explanations
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct Presets {
    /// Preset option controlling parameters for speed-precision trade-off when
    /// querying for examples. If omitted, defaults to `PRECISE`.
    #[prost(enumeration = "presets::Query", optional, tag = "1")]
    pub query: ::core::option::Option<i32>,
    /// The modality of the uploaded model, which automatically configures the
    /// distance measurement and feature normalization for the underlying example
    /// index and queries. If your model does not precisely fit one of these types,
    /// it is okay to choose the closest type.
    #[prost(enumeration = "presets::Modality", tag = "2")]
    pub modality: i32,
}
/// Nested message and enum types in `Presets`.
pub mod presets {
    /// Preset option controlling parameters for query speed-precision trade-off
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Query {
        /// More precise neighbors as a trade-off against slower response.
        Precise = 0,
        /// Faster response as a trade-off against less precise neighbors.
        Fast = 1,
    }
    impl Query {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Query::Precise => "PRECISE",
                Query::Fast => "FAST",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "PRECISE" => Some(Self::Precise),
                "FAST" => Some(Self::Fast),
                _ => None,
            }
        }
    }
    /// Preset option controlling parameters for different modalities
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Modality {
        /// Should not be set. Added as a recommended best practice for enums
        Unspecified = 0,
        /// IMAGE modality
        Image = 1,
        /// TEXT modality
        Text = 2,
        /// TABULAR modality
        Tabular = 3,
    }
    impl Modality {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Modality::Unspecified => "MODALITY_UNSPECIFIED",
                Modality::Image => "IMAGE",
                Modality::Text => "TEXT",
                Modality::Tabular => "TABULAR",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MODALITY_UNSPECIFIED" => Some(Self::Unspecified),
                "IMAGE" => Some(Self::Image),
                "TEXT" => Some(Self::Text),
                "TABULAR" => Some(Self::Tabular),
                _ => None,
            }
        }
    }
}
/// The [ExplanationSpec][google.cloud.aiplatform.v1.ExplanationSpec] entries
/// that can be overridden at [online
/// explanation][google.cloud.aiplatform.v1.PredictionService.Explain] time.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplanationSpecOverride {
    /// The parameters to be overridden. Note that the
    /// attribution method cannot be changed. If not specified,
    /// no parameter is overridden.
    #[prost(message, optional, tag = "1")]
    pub parameters: ::core::option::Option<ExplanationParameters>,
    /// The metadata to be overridden. If not specified, no metadata is overridden.
    #[prost(message, optional, tag = "2")]
    pub metadata: ::core::option::Option<ExplanationMetadataOverride>,
    /// The example-based explanations parameter overrides.
    #[prost(message, optional, tag = "3")]
    pub examples_override: ::core::option::Option<ExamplesOverride>,
}
/// The [ExplanationMetadata][google.cloud.aiplatform.v1.ExplanationMetadata]
/// entries that can be overridden at [online
/// explanation][google.cloud.aiplatform.v1.PredictionService.Explain] time.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplanationMetadataOverride {
    /// Required. Overrides the [input
    /// metadata][google.cloud.aiplatform.v1.ExplanationMetadata.inputs] of the
    /// features. The key is the name of the feature to be overridden. The keys
    /// specified here must exist in the input metadata to be overridden. If a
    /// feature is not specified here, the corresponding feature's input metadata
    /// is not overridden.
    #[prost(map = "string, message", tag = "1")]
    pub inputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        explanation_metadata_override::InputMetadataOverride,
    >,
}
/// Nested message and enum types in `ExplanationMetadataOverride`.
pub mod explanation_metadata_override {
    /// The [input
    /// metadata][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata]
    /// entries to be overridden.
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct InputMetadataOverride {
        /// Baseline inputs for this feature.
        ///
        /// This overrides the `input_baseline` field of the
        /// [ExplanationMetadata.InputMetadata][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata]
        /// object of the corresponding feature's input metadata. If it's not
        /// specified, the original baselines are not overridden.
        #[prost(message, repeated, tag = "1")]
        pub input_baselines: ::prost::alloc::vec::Vec<::prost_types::Value>,
    }
}
/// Overrides for example-based explanations.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExamplesOverride {
    /// The number of neighbors to return.
    #[prost(int32, tag = "1")]
    pub neighbor_count: i32,
    /// The number of neighbors to return that have the same crowding tag.
    #[prost(int32, tag = "2")]
    pub crowding_count: i32,
    /// Restrict the resulting nearest neighbors to respect these constraints.
    #[prost(message, repeated, tag = "3")]
    pub restrictions: ::prost::alloc::vec::Vec<ExamplesRestrictionsNamespace>,
    /// If true, return the embeddings instead of neighbors.
    #[prost(bool, tag = "4")]
    pub return_embeddings: bool,
    /// The format of the data being provided with each call.
    #[prost(enumeration = "examples_override::DataFormat", tag = "5")]
    pub data_format: i32,
}
/// Nested message and enum types in `ExamplesOverride`.
pub mod examples_override {
    /// Data format enum.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum DataFormat {
        /// Unspecified format. Must not be used.
        Unspecified = 0,
        /// Provided data is a set of model inputs.
        Instances = 1,
        /// Provided data is a set of embeddings.
        Embeddings = 2,
    }
    impl DataFormat {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                DataFormat::Unspecified => "DATA_FORMAT_UNSPECIFIED",
                DataFormat::Instances => "INSTANCES",
                DataFormat::Embeddings => "EMBEDDINGS",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "DATA_FORMAT_UNSPECIFIED" => Some(Self::Unspecified),
                "INSTANCES" => Some(Self::Instances),
                "EMBEDDINGS" => Some(Self::Embeddings),
                _ => None,
            }
        }
    }
}
/// Restrictions namespace for example-based explanations overrides.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExamplesRestrictionsNamespace {
    /// The namespace name.
    #[prost(string, tag = "1")]
    pub namespace_name: ::prost::alloc::string::String,
    /// The list of allowed tags.
    #[prost(string, repeated, tag = "2")]
    pub allow: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// The list of deny tags.
    #[prost(string, repeated, tag = "3")]
    pub deny: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// A list of boolean values.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BoolArray {
    /// A list of bool values.
    #[prost(bool, repeated, tag = "1")]
    pub values: ::prost::alloc::vec::Vec<bool>,
}
/// A list of double values.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DoubleArray {
    /// A list of double values.
    #[prost(double, repeated, tag = "1")]
    pub values: ::prost::alloc::vec::Vec<f64>,
}
/// A list of int64 values.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Int64Array {
    /// A list of int64 values.
    #[prost(int64, repeated, tag = "1")]
    pub values: ::prost::alloc::vec::Vec<i64>,
}
/// A list of string values.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StringArray {
    /// A list of string values.
    #[prost(string, repeated, tag = "1")]
    pub values: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// A tensor value type.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Tensor {
    /// The data type of tensor.
    #[prost(enumeration = "tensor::DataType", tag = "1")]
    pub dtype: i32,
    /// Shape of the tensor.
    #[prost(int64, repeated, tag = "2")]
    pub shape: ::prost::alloc::vec::Vec<i64>,
    /// Type specific representations that make it easy to create tensor protos in
    /// all languages.  Only the representation corresponding to "dtype" can
    /// be set.  The values hold the flattened representation of the tensor in
    /// row major order.
    ///
    /// [BOOL][google.aiplatform.master.Tensor.DataType.BOOL]
    #[prost(bool, repeated, tag = "3")]
    pub bool_val: ::prost::alloc::vec::Vec<bool>,
    /// [STRING][google.aiplatform.master.Tensor.DataType.STRING]
    #[prost(string, repeated, tag = "14")]
    pub string_val: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// [STRING][google.aiplatform.master.Tensor.DataType.STRING]
    #[prost(bytes = "vec", repeated, tag = "15")]
    pub bytes_val: ::prost::alloc::vec::Vec<::prost::alloc::vec::Vec<u8>>,
    /// [FLOAT][google.aiplatform.master.Tensor.DataType.FLOAT]
    #[prost(float, repeated, tag = "5")]
    pub float_val: ::prost::alloc::vec::Vec<f32>,
    /// [DOUBLE][google.aiplatform.master.Tensor.DataType.DOUBLE]
    #[prost(double, repeated, tag = "6")]
    pub double_val: ::prost::alloc::vec::Vec<f64>,
    /// [INT_8][google.aiplatform.master.Tensor.DataType.INT8]
    /// [INT_16][google.aiplatform.master.Tensor.DataType.INT16]
    /// [INT_32][google.aiplatform.master.Tensor.DataType.INT32]
    #[prost(int32, repeated, tag = "7")]
    pub int_val: ::prost::alloc::vec::Vec<i32>,
    /// [INT64][google.aiplatform.master.Tensor.DataType.INT64]
    #[prost(int64, repeated, tag = "8")]
    pub int64_val: ::prost::alloc::vec::Vec<i64>,
    /// [UINT8][google.aiplatform.master.Tensor.DataType.UINT8]
    /// [UINT16][google.aiplatform.master.Tensor.DataType.UINT16]
    /// [UINT32][google.aiplatform.master.Tensor.DataType.UINT32]
    #[prost(uint32, repeated, tag = "9")]
    pub uint_val: ::prost::alloc::vec::Vec<u32>,
    /// [UINT64][google.aiplatform.master.Tensor.DataType.UINT64]
    #[prost(uint64, repeated, tag = "10")]
    pub uint64_val: ::prost::alloc::vec::Vec<u64>,
    /// A list of tensor values.
    #[prost(message, repeated, tag = "11")]
    pub list_val: ::prost::alloc::vec::Vec<Tensor>,
    /// A map of string to tensor.
    #[prost(map = "string, message", tag = "12")]
    pub struct_val: ::std::collections::HashMap<::prost::alloc::string::String, Tensor>,
    /// Serialized raw tensor content.
    #[prost(bytes = "vec", tag = "13")]
    pub tensor_val: ::prost::alloc::vec::Vec<u8>,
}
/// Nested message and enum types in `Tensor`.
pub mod tensor {
    /// Data type of the tensor.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum DataType {
        /// Not a legal value for DataType. Used to indicate a DataType field has not
        /// been set.
        Unspecified = 0,
        /// Data types that all computation devices are expected to be
        /// capable to support.
        Bool = 1,
        String = 2,
        Float = 3,
        Double = 4,
        Int8 = 5,
        Int16 = 6,
        Int32 = 7,
        Int64 = 8,
        Uint8 = 9,
        Uint16 = 10,
        Uint32 = 11,
        Uint64 = 12,
    }
    impl DataType {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                DataType::Unspecified => "DATA_TYPE_UNSPECIFIED",
                DataType::Bool => "BOOL",
                DataType::String => "STRING",
                DataType::Float => "FLOAT",
                DataType::Double => "DOUBLE",
                DataType::Int8 => "INT8",
                DataType::Int16 => "INT16",
                DataType::Int32 => "INT32",
                DataType::Int64 => "INT64",
                DataType::Uint8 => "UINT8",
                DataType::Uint16 => "UINT16",
                DataType::Uint32 => "UINT32",
                DataType::Uint64 => "UINT64",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "DATA_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                "BOOL" => Some(Self::Bool),
                "STRING" => Some(Self::String),
                "FLOAT" => Some(Self::Float),
                "DOUBLE" => Some(Self::Double),
                "INT8" => Some(Self::Int8),
                "INT16" => Some(Self::Int16),
                "INT32" => Some(Self::Int32),
                "INT64" => Some(Self::Int64),
                "UINT8" => Some(Self::Uint8),
                "UINT16" => Some(Self::Uint16),
                "UINT32" => Some(Self::Uint32),
                "UINT64" => Some(Self::Uint64),
                _ => None,
            }
        }
    }
}
/// Request message for
/// [PredictionService.Predict][google.cloud.aiplatform.v1.PredictionService.Predict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Required. The instances that are the input to the prediction call.
    /// A DeployedModel may have an upper limit on the number of instances it
    /// supports per request, and when it is exceeded the prediction call errors
    /// in case of AutoML Models, or, in case of customer created Models, the
    /// behaviour is as documented by that Model.
    /// The schema of any single instance may be specified via Endpoint's
    /// DeployedModels' [Model's][google.cloud.aiplatform.v1.DeployedModel.model]
    /// [PredictSchemata's][google.cloud.aiplatform.v1.Model.predict_schemata]
    /// [instance_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri].
    #[prost(message, repeated, tag = "2")]
    pub instances: ::prost::alloc::vec::Vec<::prost_types::Value>,
    /// The parameters that govern the prediction. The schema of the parameters may
    /// be specified via Endpoint's DeployedModels' [Model's
    /// ][google.cloud.aiplatform.v1.DeployedModel.model]
    /// [PredictSchemata's][google.cloud.aiplatform.v1.Model.predict_schemata]
    /// [parameters_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.parameters_schema_uri].
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<::prost_types::Value>,
}
/// Response message for
/// [PredictionService.Predict][google.cloud.aiplatform.v1.PredictionService.Predict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PredictResponse {
    /// The predictions that are the output of the predictions call.
    /// The schema of any single prediction may be specified via Endpoint's
    /// DeployedModels' [Model's ][google.cloud.aiplatform.v1.DeployedModel.model]
    /// [PredictSchemata's][google.cloud.aiplatform.v1.Model.predict_schemata]
    /// [prediction_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.prediction_schema_uri].
    #[prost(message, repeated, tag = "1")]
    pub predictions: ::prost::alloc::vec::Vec<::prost_types::Value>,
    /// ID of the Endpoint's DeployedModel that served this prediction.
    #[prost(string, tag = "2")]
    pub deployed_model_id: ::prost::alloc::string::String,
    /// Output only. The resource name of the Model which is deployed as the
    /// DeployedModel that this prediction hits.
    #[prost(string, tag = "3")]
    pub model: ::prost::alloc::string::String,
    /// Output only. The version ID of the Model which is deployed as the
    /// DeployedModel that this prediction hits.
    #[prost(string, tag = "5")]
    pub model_version_id: ::prost::alloc::string::String,
    /// Output only. The [display
    /// name][google.cloud.aiplatform.v1.Model.display_name] of the Model which is
    /// deployed as the DeployedModel that this prediction hits.
    #[prost(string, tag = "4")]
    pub model_display_name: ::prost::alloc::string::String,
    /// Output only. Request-level metadata returned by the model. The metadata
    /// type will be dependent upon the model implementation.
    #[prost(message, optional, tag = "6")]
    pub metadata: ::core::option::Option<::prost_types::Value>,
}
/// Request message for
/// [PredictionService.RawPredict][google.cloud.aiplatform.v1.PredictionService.RawPredict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RawPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// The prediction input. Supports HTTP headers and arbitrary data payload.
    ///
    /// A [DeployedModel][google.cloud.aiplatform.v1.DeployedModel] may have an
    /// upper limit on the number of instances it supports per request. When this
    /// limit it is exceeded for an AutoML model, the
    /// [RawPredict][google.cloud.aiplatform.v1.PredictionService.RawPredict]
    /// method returns an error. When this limit is exceeded for a custom-trained
    /// model, the behavior varies depending on the model.
    ///
    /// You can specify the schema for each instance in the
    /// [predict_schemata.instance_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri]
    /// field when you create a [Model][google.cloud.aiplatform.v1.Model]. This
    /// schema applies when you deploy the `Model` as a `DeployedModel` to an
    /// [Endpoint][google.cloud.aiplatform.v1.Endpoint] and use the `RawPredict`
    /// method.
    #[prost(message, optional, tag = "2")]
    pub http_body: ::core::option::Option<super::super::super::api::HttpBody>,
}
/// Request message for
/// [PredictionService.StreamRawPredict][google.cloud.aiplatform.v1.PredictionService.StreamRawPredict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamRawPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// The prediction input. Supports HTTP headers and arbitrary data payload.
    #[prost(message, optional, tag = "2")]
    pub http_body: ::core::option::Option<super::super::super::api::HttpBody>,
}
/// Request message for
/// [PredictionService.DirectPredict][google.cloud.aiplatform.v1.PredictionService.DirectPredict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DirectPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// The prediction input.
    #[prost(message, repeated, tag = "2")]
    pub inputs: ::prost::alloc::vec::Vec<Tensor>,
    /// The parameters that govern the prediction.
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Response message for
/// [PredictionService.DirectPredict][google.cloud.aiplatform.v1.PredictionService.DirectPredict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DirectPredictResponse {
    /// The prediction output.
    #[prost(message, repeated, tag = "1")]
    pub outputs: ::prost::alloc::vec::Vec<Tensor>,
    /// The parameters that govern the prediction.
    #[prost(message, optional, tag = "2")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Request message for
/// [PredictionService.DirectRawPredict][google.cloud.aiplatform.v1.PredictionService.DirectRawPredict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DirectRawPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Fully qualified name of the API method being invoked to perform
    /// predictions.
    ///
    /// Format:
    /// `/namespace.Service/Method/`
    /// Example:
    /// `/tensorflow.serving.PredictionService/Predict`
    #[prost(string, tag = "2")]
    pub method_name: ::prost::alloc::string::String,
    /// The prediction input.
    #[prost(bytes = "vec", tag = "3")]
    pub input: ::prost::alloc::vec::Vec<u8>,
}
/// Response message for
/// [PredictionService.DirectRawPredict][google.cloud.aiplatform.v1.PredictionService.DirectRawPredict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DirectRawPredictResponse {
    /// The prediction output.
    #[prost(bytes = "vec", tag = "1")]
    pub output: ::prost::alloc::vec::Vec<u8>,
}
/// Request message for
/// [PredictionService.StreamDirectPredict][google.cloud.aiplatform.v1.PredictionService.StreamDirectPredict].
///
/// The first message must contain
/// [endpoint][google.cloud.aiplatform.v1.StreamDirectPredictRequest.endpoint]
/// field and optionally [input][]. The subsequent messages must contain
/// [input][].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamDirectPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Optional. The prediction input.
    #[prost(message, repeated, tag = "2")]
    pub inputs: ::prost::alloc::vec::Vec<Tensor>,
    /// Optional. The parameters that govern the prediction.
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Response message for
/// [PredictionService.StreamDirectPredict][google.cloud.aiplatform.v1.PredictionService.StreamDirectPredict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamDirectPredictResponse {
    /// The prediction output.
    #[prost(message, repeated, tag = "1")]
    pub outputs: ::prost::alloc::vec::Vec<Tensor>,
    /// The parameters that govern the prediction.
    #[prost(message, optional, tag = "2")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Request message for
/// [PredictionService.StreamDirectRawPredict][google.cloud.aiplatform.v1.PredictionService.StreamDirectRawPredict].
///
/// The first message must contain
/// [endpoint][google.cloud.aiplatform.v1.StreamDirectRawPredictRequest.endpoint]
/// and
/// [method_name][google.cloud.aiplatform.v1.StreamDirectRawPredictRequest.method_name]
/// fields and optionally
/// [input][google.cloud.aiplatform.v1.StreamDirectRawPredictRequest.input]. The
/// subsequent messages must contain
/// [input][google.cloud.aiplatform.v1.StreamDirectRawPredictRequest.input].
/// [method_name][google.cloud.aiplatform.v1.StreamDirectRawPredictRequest.method_name]
/// in the subsequent messages have no effect.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamDirectRawPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Optional. Fully qualified name of the API method being invoked to perform
    /// predictions.
    ///
    /// Format:
    /// `/namespace.Service/Method/`
    /// Example:
    /// `/tensorflow.serving.PredictionService/Predict`
    #[prost(string, tag = "2")]
    pub method_name: ::prost::alloc::string::String,
    /// Optional. The prediction input.
    #[prost(bytes = "vec", tag = "3")]
    pub input: ::prost::alloc::vec::Vec<u8>,
}
/// Response message for
/// [PredictionService.StreamDirectRawPredict][google.cloud.aiplatform.v1.PredictionService.StreamDirectRawPredict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamDirectRawPredictResponse {
    /// The prediction output.
    #[prost(bytes = "vec", tag = "1")]
    pub output: ::prost::alloc::vec::Vec<u8>,
}
/// Request message for
/// [PredictionService.StreamingPredict][google.cloud.aiplatform.v1.PredictionService.StreamingPredict].
///
/// The first message must contain
/// [endpoint][google.cloud.aiplatform.v1.StreamingPredictRequest.endpoint] field
/// and optionally [input][]. The subsequent messages must contain [input][].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamingPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// The prediction input.
    #[prost(message, repeated, tag = "2")]
    pub inputs: ::prost::alloc::vec::Vec<Tensor>,
    /// The parameters that govern the prediction.
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Response message for
/// [PredictionService.StreamingPredict][google.cloud.aiplatform.v1.PredictionService.StreamingPredict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamingPredictResponse {
    /// The prediction output.
    #[prost(message, repeated, tag = "1")]
    pub outputs: ::prost::alloc::vec::Vec<Tensor>,
    /// The parameters that govern the prediction.
    #[prost(message, optional, tag = "2")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Request message for
/// [PredictionService.StreamingRawPredict][google.cloud.aiplatform.v1.PredictionService.StreamingRawPredict].
///
/// The first message must contain
/// [endpoint][google.cloud.aiplatform.v1.StreamingRawPredictRequest.endpoint]
/// and
/// [method_name][google.cloud.aiplatform.v1.StreamingRawPredictRequest.method_name]
/// fields and optionally
/// [input][google.cloud.aiplatform.v1.StreamingRawPredictRequest.input]. The
/// subsequent messages must contain
/// [input][google.cloud.aiplatform.v1.StreamingRawPredictRequest.input].
/// [method_name][google.cloud.aiplatform.v1.StreamingRawPredictRequest.method_name]
/// in the subsequent messages have no effect.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamingRawPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Fully qualified name of the API method being invoked to perform
    /// predictions.
    ///
    /// Format:
    /// `/namespace.Service/Method/`
    /// Example:
    /// `/tensorflow.serving.PredictionService/Predict`
    #[prost(string, tag = "2")]
    pub method_name: ::prost::alloc::string::String,
    /// The prediction input.
    #[prost(bytes = "vec", tag = "3")]
    pub input: ::prost::alloc::vec::Vec<u8>,
}
/// Response message for
/// [PredictionService.StreamingRawPredict][google.cloud.aiplatform.v1.PredictionService.StreamingRawPredict].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamingRawPredictResponse {
    /// The prediction output.
    #[prost(bytes = "vec", tag = "1")]
    pub output: ::prost::alloc::vec::Vec<u8>,
}
/// Request message for
/// [PredictionService.Explain][google.cloud.aiplatform.v1.PredictionService.Explain].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplainRequest {
    /// Required. The name of the Endpoint requested to serve the explanation.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Required. The instances that are the input to the explanation call.
    /// A DeployedModel may have an upper limit on the number of instances it
    /// supports per request, and when it is exceeded the explanation call errors
    /// in case of AutoML Models, or, in case of customer created Models, the
    /// behaviour is as documented by that Model.
    /// The schema of any single instance may be specified via Endpoint's
    /// DeployedModels' [Model's][google.cloud.aiplatform.v1.DeployedModel.model]
    /// [PredictSchemata's][google.cloud.aiplatform.v1.Model.predict_schemata]
    /// [instance_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri].
    #[prost(message, repeated, tag = "2")]
    pub instances: ::prost::alloc::vec::Vec<::prost_types::Value>,
    /// The parameters that govern the prediction. The schema of the parameters may
    /// be specified via Endpoint's DeployedModels' [Model's
    /// ][google.cloud.aiplatform.v1.DeployedModel.model]
    /// [PredictSchemata's][google.cloud.aiplatform.v1.Model.predict_schemata]
    /// [parameters_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.parameters_schema_uri].
    #[prost(message, optional, tag = "4")]
    pub parameters: ::core::option::Option<::prost_types::Value>,
    /// If specified, overrides the
    /// [explanation_spec][google.cloud.aiplatform.v1.DeployedModel.explanation_spec]
    /// of the DeployedModel. Can be used for explaining prediction results with
    /// different configurations, such as:
    ///   - Explaining top-5 predictions results as opposed to top-1;
    ///   - Increasing path count or step count of the attribution methods to reduce
    ///     approximate errors;
    ///   - Using different baselines for explaining the prediction results.
    #[prost(message, optional, tag = "5")]
    pub explanation_spec_override: ::core::option::Option<ExplanationSpecOverride>,
    /// If specified, this ExplainRequest will be served by the chosen
    /// DeployedModel, overriding
    /// [Endpoint.traffic_split][google.cloud.aiplatform.v1.Endpoint.traffic_split].
    #[prost(string, tag = "3")]
    pub deployed_model_id: ::prost::alloc::string::String,
}
/// Response message for
/// [PredictionService.Explain][google.cloud.aiplatform.v1.PredictionService.Explain].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplainResponse {
    /// The explanations of the Model's
    /// [PredictResponse.predictions][google.cloud.aiplatform.v1.PredictResponse.predictions].
    ///
    /// It has the same number of elements as
    /// [instances][google.cloud.aiplatform.v1.ExplainRequest.instances] to be
    /// explained.
    #[prost(message, repeated, tag = "1")]
    pub explanations: ::prost::alloc::vec::Vec<Explanation>,
    /// ID of the Endpoint's DeployedModel that served this explanation.
    #[prost(string, tag = "2")]
    pub deployed_model_id: ::prost::alloc::string::String,
    /// The predictions that are the output of the predictions call.
    /// Same as
    /// [PredictResponse.predictions][google.cloud.aiplatform.v1.PredictResponse.predictions].
    #[prost(message, repeated, tag = "3")]
    pub predictions: ::prost::alloc::vec::Vec<::prost_types::Value>,
}
/// Request message for [PredictionService.CountTokens][].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CountTokensRequest {
    /// Required. The name of the Endpoint requested to perform token counting.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Required. The name of the publisher model requested to serve the
    /// prediction. Format:
    /// `projects/{project}/locations/{location}/publishers/*/models/*`
    #[prost(string, tag = "3")]
    pub model: ::prost::alloc::string::String,
    /// Required. The instances that are the input to token counting call.
    /// Schema is identical to the prediction schema of the underlying model.
    #[prost(message, repeated, tag = "2")]
    pub instances: ::prost::alloc::vec::Vec<::prost_types::Value>,
    /// Required. Input content.
    #[prost(message, repeated, tag = "4")]
    pub contents: ::prost::alloc::vec::Vec<Content>,
}
/// Response message for [PredictionService.CountTokens][].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct CountTokensResponse {
    /// The total number of tokens counted across all instances from the request.
    #[prost(int32, tag = "1")]
    pub total_tokens: i32,
    /// The total number of billable characters counted across all instances from
    /// the request.
    #[prost(int32, tag = "2")]
    pub total_billable_characters: i32,
}
/// Request message for \[PredictionService.GenerateContent\].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerateContentRequest {
    /// Required. The name of the publisher model requested to serve the
    /// prediction. Format:
    /// `projects/{project}/locations/{location}/publishers/*/models/*`
    #[prost(string, tag = "5")]
    pub model: ::prost::alloc::string::String,
    /// Required. The content of the current conversation with the model.
    ///
    /// For single-turn queries, this is a single instance. For multi-turn queries,
    /// this is a repeated field that contains conversation history + latest
    /// request.
    #[prost(message, repeated, tag = "2")]
    pub contents: ::prost::alloc::vec::Vec<Content>,
    /// Optional. The user provided system instructions for the model.
    /// Note: only text should be used in parts and content in each part will be in
    /// a separate paragraph.
    #[prost(message, optional, tag = "8")]
    pub system_instruction: ::core::option::Option<Content>,
    /// Optional. A list of `Tools` the model may use to generate the next
    /// response.
    ///
    /// A `Tool` is a piece of code that enables the system to interact with
    /// external systems to perform an action, or set of actions, outside of
    /// knowledge and scope of the model.
    #[prost(message, repeated, tag = "6")]
    pub tools: ::prost::alloc::vec::Vec<Tool>,
    /// Optional. Tool config. This config is shared for all tools provided in the
    /// request.
    #[prost(message, optional, tag = "7")]
    pub tool_config: ::core::option::Option<ToolConfig>,
    /// Optional. Per request settings for blocking unsafe content.
    /// Enforced on GenerateContentResponse.candidates.
    #[prost(message, repeated, tag = "3")]
    pub safety_settings: ::prost::alloc::vec::Vec<SafetySetting>,
    /// Optional. Generation config.
    #[prost(message, optional, tag = "4")]
    pub generation_config: ::core::option::Option<GenerationConfig>,
}
/// Response message for \[PredictionService.GenerateContent\].
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerateContentResponse {
    /// Output only. Generated candidates.
    #[prost(message, repeated, tag = "2")]
    pub candidates: ::prost::alloc::vec::Vec<Candidate>,
    /// Output only. Content filter results for a prompt sent in the request.
    /// Note: Sent only in the first stream chunk.
    /// Only happens when no candidates were generated due to content violations.
    #[prost(message, optional, tag = "3")]
    pub prompt_feedback: ::core::option::Option<
        generate_content_response::PromptFeedback,
    >,
    /// Usage metadata about the response(s).
    #[prost(message, optional, tag = "4")]
    pub usage_metadata: ::core::option::Option<generate_content_response::UsageMetadata>,
}
/// Nested message and enum types in `GenerateContentResponse`.
pub mod generate_content_response {
    /// Content filter results for a prompt sent in the request.
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct PromptFeedback {
        /// Output only. Blocked reason.
        #[prost(enumeration = "prompt_feedback::BlockedReason", tag = "1")]
        pub block_reason: i32,
        /// Output only. Safety ratings.
        #[prost(message, repeated, tag = "2")]
        pub safety_ratings: ::prost::alloc::vec::Vec<super::SafetyRating>,
        /// Output only. A readable block reason message.
        #[prost(string, tag = "3")]
        pub block_reason_message: ::prost::alloc::string::String,
    }
    /// Nested message and enum types in `PromptFeedback`.
    pub mod prompt_feedback {
        /// Blocked reason enumeration.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum BlockedReason {
            /// Unspecified blocked reason.
            Unspecified = 0,
            /// Candidates blocked due to safety.
            Safety = 1,
            /// Candidates blocked due to other reason.
            Other = 2,
            /// Candidates blocked due to the terms which are included from the
            /// terminology blocklist.
            Blocklist = 3,
            /// Candidates blocked due to prohibited content.
            ProhibitedContent = 4,
        }
        impl BlockedReason {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    BlockedReason::Unspecified => "BLOCKED_REASON_UNSPECIFIED",
                    BlockedReason::Safety => "SAFETY",
                    BlockedReason::Other => "OTHER",
                    BlockedReason::Blocklist => "BLOCKLIST",
                    BlockedReason::ProhibitedContent => "PROHIBITED_CONTENT",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "BLOCKED_REASON_UNSPECIFIED" => Some(Self::Unspecified),
                    "SAFETY" => Some(Self::Safety),
                    "OTHER" => Some(Self::Other),
                    "BLOCKLIST" => Some(Self::Blocklist),
                    "PROHIBITED_CONTENT" => Some(Self::ProhibitedContent),
                    _ => None,
                }
            }
        }
    }
    /// Usage metadata about response(s).
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, Copy, PartialEq, ::prost::Message)]
    pub struct UsageMetadata {
        /// Number of tokens in the request.
        #[prost(int32, tag = "1")]
        pub prompt_token_count: i32,
        /// Number of tokens in the response(s).
        #[prost(int32, tag = "2")]
        pub candidates_token_count: i32,
        #[prost(int32, tag = "3")]
        pub total_token_count: i32,
    }
}
/// Generated client implementations.
pub mod prediction_service_client {
    #![allow(unused_variables, dead_code, missing_docs, clippy::let_unit_value)]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// A service for online predictions and explanations.
    #[derive(Debug, Clone)]
    pub struct PredictionServiceClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl PredictionServiceClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> PredictionServiceClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::BoxBody>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> PredictionServiceClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::BoxBody>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
            >>::Error: Into<StdError> + Send + Sync,
        {
            PredictionServiceClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Perform an online prediction.
        pub async fn predict(
            &mut self,
            request: impl tonic::IntoRequest<super::PredictRequest>,
        ) -> std::result::Result<
            tonic::Response<super::PredictResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/Predict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "Predict",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Perform an online prediction with an arbitrary HTTP payload.
        ///
        /// The response includes the following HTTP headers:
        ///
        /// * `X-Vertex-AI-Endpoint-Id`: ID of the
        /// [Endpoint][google.cloud.aiplatform.v1.Endpoint] that served this
        /// prediction.
        ///
        /// * `X-Vertex-AI-Deployed-Model-Id`: ID of the Endpoint's
        /// [DeployedModel][google.cloud.aiplatform.v1.DeployedModel] that served this
        /// prediction.
        pub async fn raw_predict(
            &mut self,
            request: impl tonic::IntoRequest<super::RawPredictRequest>,
        ) -> std::result::Result<
            tonic::Response<super::super::super::super::api::HttpBody>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/RawPredict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "RawPredict",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Perform a streaming online prediction with an arbitrary HTTP payload.
        pub async fn stream_raw_predict(
            &mut self,
            request: impl tonic::IntoRequest<super::StreamRawPredictRequest>,
        ) -> std::result::Result<
            tonic::Response<
                tonic::codec::Streaming<super::super::super::super::api::HttpBody>,
            >,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamRawPredict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamRawPredict",
                    ),
                );
            self.inner.server_streaming(req, path, codec).await
        }
        /// Perform an unary online prediction request to a gRPC model server for
        /// Vertex first-party products and frameworks.
        pub async fn direct_predict(
            &mut self,
            request: impl tonic::IntoRequest<super::DirectPredictRequest>,
        ) -> std::result::Result<
            tonic::Response<super::DirectPredictResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/DirectPredict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "DirectPredict",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Perform an unary online prediction request to a gRPC model server for
        /// custom containers.
        pub async fn direct_raw_predict(
            &mut self,
            request: impl tonic::IntoRequest<super::DirectRawPredictRequest>,
        ) -> std::result::Result<
            tonic::Response<super::DirectRawPredictResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/DirectRawPredict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "DirectRawPredict",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Perform a streaming online prediction request to a gRPC model server for
        /// Vertex first-party products and frameworks.
        pub async fn stream_direct_predict(
            &mut self,
            request: impl tonic::IntoStreamingRequest<
                Message = super::StreamDirectPredictRequest,
            >,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::StreamDirectPredictResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamDirectPredict",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamDirectPredict",
                    ),
                );
            self.inner.streaming(req, path, codec).await
        }
        /// Perform a streaming online prediction request to a gRPC model server for
        /// custom containers.
        pub async fn stream_direct_raw_predict(
            &mut self,
            request: impl tonic::IntoStreamingRequest<
                Message = super::StreamDirectRawPredictRequest,
            >,
        ) -> std::result::Result<
            tonic::Response<
                tonic::codec::Streaming<super::StreamDirectRawPredictResponse>,
            >,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamDirectRawPredict",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamDirectRawPredict",
                    ),
                );
            self.inner.streaming(req, path, codec).await
        }
        /// Perform a streaming online prediction request for Vertex first-party
        /// products and frameworks.
        pub async fn streaming_predict(
            &mut self,
            request: impl tonic::IntoStreamingRequest<
                Message = super::StreamingPredictRequest,
            >,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::StreamingPredictResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamingPredict",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamingPredict",
                    ),
                );
            self.inner.streaming(req, path, codec).await
        }
        /// Perform a server-side streaming online prediction request for Vertex
        /// LLM streaming.
        pub async fn server_streaming_predict(
            &mut self,
            request: impl tonic::IntoRequest<super::StreamingPredictRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::StreamingPredictResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/ServerStreamingPredict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "ServerStreamingPredict",
                    ),
                );
            self.inner.server_streaming(req, path, codec).await
        }
        /// Perform a streaming online prediction request through gRPC.
        pub async fn streaming_raw_predict(
            &mut self,
            request: impl tonic::IntoStreamingRequest<
                Message = super::StreamingRawPredictRequest,
            >,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::StreamingRawPredictResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamingRawPredict",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamingRawPredict",
                    ),
                );
            self.inner.streaming(req, path, codec).await
        }
        /// Perform an online explanation.
        ///
        /// If
        /// [deployed_model_id][google.cloud.aiplatform.v1.ExplainRequest.deployed_model_id]
        /// is specified, the corresponding DeployModel must have
        /// [explanation_spec][google.cloud.aiplatform.v1.DeployedModel.explanation_spec]
        /// populated. If
        /// [deployed_model_id][google.cloud.aiplatform.v1.ExplainRequest.deployed_model_id]
        /// is not specified, all DeployedModels must have
        /// [explanation_spec][google.cloud.aiplatform.v1.DeployedModel.explanation_spec]
        /// populated.
        pub async fn explain(
            &mut self,
            request: impl tonic::IntoRequest<super::ExplainRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ExplainResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/Explain",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "Explain",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Generate content with multimodal inputs.
        pub async fn generate_content(
            &mut self,
            request: impl tonic::IntoRequest<super::GenerateContentRequest>,
        ) -> std::result::Result<
            tonic::Response<super::GenerateContentResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/GenerateContent",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "GenerateContent",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Generate content with multimodal inputs with streaming support.
        pub async fn stream_generate_content(
            &mut self,
            request: impl tonic::IntoRequest<super::GenerateContentRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::GenerateContentResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::new(
                        tonic::Code::Unknown,
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamGenerateContent",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamGenerateContent",
                    ),
                );
            self.inner.server_streaming(req, path, codec).await
        }
    }
}
